[2025-03-22 16:04:44,207] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 16:04:44,209] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/confluentinc-kafka-connect-jdbc-10.8.2:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 16:04:44,210] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 16:04:44,220] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:04:44,328] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:04:44,331] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:04:44,336] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:04:44,336] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:04:44,340] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:04:44,340] INFO Scanning plugins with ServiceLoaderScanner took 120 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 16:04:44,341] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:04:44,363] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:04:44,363] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:04:44,379] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:04:44,379] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:04:45,090] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:04:45,090] INFO Scanning plugins with ReflectionScanner took 749 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 16:04:45,094] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 16:04:45,094] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,094] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,094] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,094] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,094] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,094] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,095] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,096] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:04:45,097] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,097] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,098] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,099] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,100] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:04:45,120] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 16:04:45,120] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 16:04:45,121] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 16:04:45,144] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 16:04:45,145] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,145] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,145] INFO Kafka startTimeMs: 1742659485145 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,246] INFO Kafka cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 16:04:45,247] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:04:45,249] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:04:45,249] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:04:45,249] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:04:45,252] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 16:04:45,256] INFO Logging initialized @1264ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 16:04:45,271] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 16:04:45,271] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 16:04:45,282] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 16:04:45,292] INFO Started http_8083@af007d6{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 16:04:45,293] INFO Started @1300ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 16:04:45,300] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:04:45,300] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 16:04:45,300] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:04:45,300] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 16:04:45,301] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:04:45,301] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 16:04:45,302] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:04:45,308] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,308] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,308] INFO Kafka startTimeMs: 1742659485308 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,310] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:04:45,310] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:04:45,317] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:04:45,328] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,328] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,328] INFO Kafka startTimeMs: 1742659485328 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,329] INFO Kafka Connect worker initialization took 1121ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 16:04:45,329] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 16:04:45,330] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 16:04:45,330] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 16:04:45,331] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 16:04:45,331] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 16:04:45,331] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 16:04:45,332] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 16:04:45,334] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 16:04:45,334] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,334] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,334] INFO Kafka startTimeMs: 1742659485334 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,345] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 16:04:45,356] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:04:45,361] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 16:04:45,361] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 16:04:45,362] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 16:04:45,366] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,376] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:04:45,376] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,376] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,376] INFO Kafka startTimeMs: 1742659485376 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,385] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:04:45,386] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,393] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,408] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:04:45,408] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,408] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,408] INFO Kafka startTimeMs: 1742659485408 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,415] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,417] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,418] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,419] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,435] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,435] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,435] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,435] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,436] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,437] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,437] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,437] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,437] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,438] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,439] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,439] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,439] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,469] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 16:04:45,470] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 16:04:45,470] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 16:04:45,470] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 16:04:45,470] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 16:04:45,474] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:04:45,476] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,479] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:04:45,479] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,479] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,480] INFO Kafka startTimeMs: 1742659485479 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,480] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:04:45,480] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,482] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,485] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:04:45,485] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,485] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,485] INFO Kafka startTimeMs: 1742659485485 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,486] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,487] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 16:04:45,487] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,487] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,487] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,487] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,487] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,499] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,499] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,499] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,499] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,499] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,509] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 16:04:45,509] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 16:04:45,510] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 16:04:45,510] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 16:04:45,515] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:04:45,516] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,518] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:04:45,518] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,518] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,518] INFO Kafka startTimeMs: 1742659485518 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,520] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:04:45,522] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,521] INFO [Producer clientId=connect-cluster-configs] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,524] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:04:45,524] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,524] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,524] INFO Kafka startTimeMs: 1742659485524 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,526] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,526] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 16:04:45,526] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:04:45,531] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:04:45,536] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 16:04:45,536] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 16:04:45,536] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 16:04:45,537] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 16:04:45,537] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 16:04:45,537] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 16:04:45,537] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 16:04:45,542] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,543] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 16:04:45,545] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:04:45,545] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:04:45,548] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:04:45,550] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:04:45,550] INFO Started o.e.j.s.ServletContextHandler@294bb6ae{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 16:04:45,550] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 16:04:45,550] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 16:04:45,557] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:04:45,558] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', leaderUrl='http://127.0.1.1:8083/', offset=33, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed, mysql-sink-bluesky], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0, mysql-sink-bluesky-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:04:45,558] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-22 16:04:45,558] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 33, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-22 16:04:45,560] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 33 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-22 16:04:45,560] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 33 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:04:45,561] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 16:04:45,561] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 16:04:45,562] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 16:04:45,562] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 16:04:45,563] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 16:04:45,565] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 16:04:45,565] ERROR [mysql-sink-bluesky|worker] Failed to start connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:337)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:313)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:2105)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$44(DistributedHerder.java:2111)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:04:45,565] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 16:04:45,566] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 16:04:45,565] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 16:04:45,565] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 16:04:45,565] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 16:04:45,569] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:969)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:949)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:949)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:967)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2004)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$39(DistributedHerder.java:2056)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:04:45,570] ERROR [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Couldn't instantiate task mysql-sink-bluesky-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2058)
org.apache.kafka.connect.errors.ConnectException: Failed to start task mysql-sink-bluesky-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2049)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$39(DistributedHerder.java:2056)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:04:45,570] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:04:45,569] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:04:45,571] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 16:04:45,570] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 16:04:45,572] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,572] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,573] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,574] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,574] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 16:04:45,574] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 16:04:45,575] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 16:04:45,575] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 16:04:45,575] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:04:45,575] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-22 16:04:45,575] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:04:45,575] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-22 16:04:45,575] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 16:04:45,577] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 16:04:45,577] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:04:45,577] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 16:04:45,577] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 16:04:45,577] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 16:04:45,577] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 16:04:45,577] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 16:04:45,579] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:04:45,578] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 16:04:45,579] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,578] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 16:04:45,579] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:04:45,579] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 16:04:45,579] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 16:04:45,580] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,579] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 16:04:45,580] INFO [file-source-distributed|worker] Starting file source connector reading from /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-22 16:04:45,580] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:04:45,580] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 16:04:45,582] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:04:45,582] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,582] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,583] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,583] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742659485582 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,584] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:04:45,585] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:04:45,586] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,585] ERROR [mysql-sink-bluesky|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'mysql-sink-bluesky' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2113)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: mysql-sink-bluesky
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$42(DistributedHerder.java:2083)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:339)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:2105)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$44(DistributedHerder.java:2111)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:313)
	... 6 more
[2025-03-22 16:04:45,588] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 16:04:45,589] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 16:04:45,590] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:04:45,590] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:04:45,590] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:04:45,590] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742659485590 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:04:45,592] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:04:45,592] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:04:45,593] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:04:45,594] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 16:04:45,594] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,595] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:04:45,596] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:04:45,601] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 16:04:45,604] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 16:04:45,666] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 16:04:46,309] INFO [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 16:04:51,000] INFO Successfully processed removal of connector 'mysql-sink-bluesky' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 16:04:51,000] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector mysql-sink-bluesky config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-03-22 16:04:51,001] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-03-22 16:04:51,001] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 16:04:51,001] WARN [mysql-sink-bluesky|worker] Ignoring stop request for unowned connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:454)
[2025-03-22 16:04:51,001] WARN [mysql-sink-bluesky|worker] Ignoring await stop request for non-present connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:475)
[2025-03-22 16:04:51,001] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:04:51,001] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:04:51,003] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:04:51,005] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:04:51,006] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 16:04:51,006] WARN [mysql-sink-bluesky|task-0] Ignoring stop request for unowned task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1043)
[2025-03-22 16:04:51,006] WARN [mysql-sink-bluesky|worker] Ignoring stop request for unowned connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:454)
[2025-03-22 16:04:51,006] WARN [mysql-sink-bluesky|worker] Ignoring await stop request for non-present connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:475)
[2025-03-22 16:04:51,006] WARN [mysql-sink-bluesky|task-0] Ignoring await stop request for non-present task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1069)
[2025-03-22 16:04:51,006] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-03-22 16:04:51,009] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-03-22 16:04:51,009] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', leaderUrl='http://127.0.1.1:8083/', offset=35, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0], revokedConnectorIds=[mysql-sink-bluesky], revokedTaskIds=[mysql-sink-bluesky-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:04:51,009] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 35 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:04:51,010] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:04:51,010] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:04:51,010] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:04:51,011] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:04:51,013] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:16:04:50 +0000] "DELETE /connectors/mysql-sink-bluesky HTTP/1.1" 204 0 "-" "curl/8.5.0" 35 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 16:04:51,015] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:04:51,016] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-09cb548e-fd64-4a74-8f41-b3597c3f242e', leaderUrl='http://127.0.1.1:8083/', offset=35, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:04:51,016] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 35 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:04:51,016] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:04:51,309] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:04:53,946] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:949)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:949)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:662)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:574)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:04:53,953] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:16:04:53 +0000] "POST /connectors HTTP/1.1" 500 1837 "-" "curl/8.5.0" 37 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 16:05:51,309] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:06:51,309] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:07:51,311] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:08:51,315] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:09:45,439] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:09:51,316] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:10:51,321] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:11:14,423] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,424] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,424] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,424] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cancelled in-flight FETCH request with correlation id 785 due to node 0 being disconnected (elapsed time since creation: 422ms, elapsed time since send: 422ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,424] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,424] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-03-22 16:11:14,424] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Error sending fetch request (sessionId=346598638, epoch=776) to node 0: (org.apache.kafka.clients.FetchSessionHandler:617)
org.apache.kafka.common.errors.DisconnectException
[2025-03-22 16:11:14,425] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,423] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,425] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,424] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,425] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,425] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,426] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,426] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,426] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,426] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cancelled in-flight FETCH request with correlation id 789 due to node 0 being disconnected (elapsed time since creation: 425ms, elapsed time since send: 425ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,426] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,427] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Error sending fetch request (sessionId=165654960, epoch=780) to node 0: (org.apache.kafka.clients.FetchSessionHandler:617)
org.apache.kafka.common.errors.DisconnectException
[2025-03-22 16:11:14,427] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,427] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,427] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,428] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,428] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cancelled in-flight METADATA request with correlation id 142 due to node 0 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, throttle time: 0ms, request timeout: 40000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,428] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cancelled in-flight FIND_COORDINATOR request with correlation id 141 due to node 0 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, throttle time: 0ms, request timeout: 40000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,428] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cancelled in-flight FETCH request with correlation id 785 due to node 0 being disconnected (elapsed time since creation: 427ms, elapsed time since send: 427ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cancelled in-flight METADATA request with correlation id 786 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Error sending fetch request (sessionId=2065688148, epoch=776) to node 0: (org.apache.kafka.clients.FetchSessionHandler:617)
org.apache.kafka.common.errors.DisconnectException
[2025-03-22 16:11:14,429] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cancelled in-flight METADATA request with correlation id 6 due to node 0 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,429] INFO [Producer clientId=connect-cluster-configs] Cancelled in-flight METADATA request with correlation id 8 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:363)
[2025-03-22 16:11:14,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,515] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,524] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,524] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,525] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,525] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,526] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,526] WARN [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,527] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,527] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,529] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,529] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,531] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,531] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,540] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,540] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,541] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,541] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,546] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,546] WARN [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,625] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,625] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,625] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,626] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,637] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,637] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,684] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,685] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,698] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,698] WARN [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,715] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,716] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,730] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,730] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,751] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,751] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,755] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,755] WARN [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,773] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,774] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,829] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,829] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,861] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,861] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,892] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,892] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,910] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,910] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,957] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,957] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,961] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,961] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,968] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,969] WARN [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:14,983] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:14,983] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,211] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,212] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,219] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,219] WARN [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,234] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,234] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,301] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,302] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,347] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,347] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,347] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,347] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,365] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,365] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,393] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,393] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,435] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,435] WARN [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,469] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,469] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:15,960] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:15,960] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,115] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,115] WARN [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,155] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,156] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,165] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,205] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,205] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,273] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,273] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,319] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,319] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,359] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,359] WARN [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,359] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,359] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,418] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,418] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:16,428] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 16:11:16,428] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 16:11:16,432] INFO Stopped http_8083@af007d6{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 16:11:16,432] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 16:11:16,435] INFO Stopped o.e.j.s.ServletContextHandler@294bb6ae{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 16:11:16,435] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 16:11:16,435] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 16:11:16,436] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 16:11:16,436] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 16:11:16,436] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 16:11:16,436] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 16:11:16,436] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 16:11:16,436] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 16:11:16,437] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 16:11:16,437] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 16:11:16,437] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 16:11:16,438] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 16:11:16,438] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 16:11:16,438] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 16:11:16,440] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:16,440] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:16,440] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:16,440] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:16,440] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:16,884] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:16,885] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,071] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,072] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,072] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 16:11:17,084] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:17,084] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:17,084] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:17,085] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:17,086] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:17,093] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 16:11:17,095] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 16:11:17,146] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,146] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,152] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,152] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,211] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,212] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,277] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,278] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,294] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,294] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,889] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,890] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:17,977] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:17,978] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,099] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,100] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,157] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,158] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,214] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,215] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,281] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,282] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,335] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,336] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,845] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,846] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:18,891] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:18,892] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,023] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,024] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,183] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,184] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,219] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,220] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,286] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,287] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,286] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,290] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,816] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,817] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:19,895] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:19,895] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,045] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,046] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,206] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,207] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,221] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,221] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,290] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,292] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,314] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,315] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,818] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,819] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:20,901] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:20,902] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,078] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,079] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,133] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,134] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,168] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,169] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,238] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,238] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,294] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,295] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,736] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,737] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:21,927] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:21,928] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,096] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,097] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,143] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,144] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,175] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,175] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,257] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,257] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,299] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,299] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,659] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,660] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:22,929] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:22,930] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,115] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,116] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,147] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,147] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,176] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,176] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,274] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,275] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,324] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,325] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,581] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,582] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:23,932] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:23,933] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,139] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,140] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,148] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,148] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,178] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,178] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,308] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,309] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,329] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,329] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,585] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,586] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,935] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,936] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:24,955] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:24,955] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,148] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,149] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,151] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,152] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,330] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,331] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,330] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,335] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,593] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,594] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,958] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,959] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:25,961] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:25,962] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,155] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,156] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,167] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,167] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,336] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,337] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,354] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,355] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,596] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,597] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,974] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,974] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:26,975] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:26,977] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,157] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,159] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,170] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,171] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,339] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,340] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,380] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,381] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,546] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,546] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,941] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,942] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:27,988] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:27,989] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:28,146] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:28,147] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:28,157] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:28,158] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:28,345] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:28,346] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:28,398] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:28,399] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:28,474] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:28,475] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:28,863] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:28,864] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,014] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,015] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,173] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,174] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,173] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,177] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,348] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,349] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,364] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,365] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,419] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,421] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:29,865] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:29,866] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,031] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,032] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,179] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,181] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,204] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,204] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,255] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,255] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,351] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,351] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,441] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,441] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:30,868] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:30,869] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,053] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,054] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,169] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,170] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,218] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,219] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,221] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,222] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,354] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,355] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,461] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,462] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,874] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,875] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:31,967] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:31,968] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,172] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,174] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,199] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,200] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,219] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,219] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,331] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,331] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,483] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,484] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,789] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,790] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:32,993] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:32,994] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:33,124] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:33,125] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:33,175] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:33,176] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:33,223] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:33,224] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:33,288] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:33,289] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:33,498] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:33,499] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:33,704] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:33,705] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,022] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,022] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,127] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,128] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,178] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,179] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,225] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,226] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,299] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,299] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,517] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,518] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,626] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,627] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:34,978] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:34,979] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,035] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,035] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,137] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,137] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,180] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,181] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,301] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,302] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,443] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,445] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,636] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,638] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:35,832] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:35,833] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,055] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,056] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,140] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,141] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,157] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,157] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,185] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,186] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,468] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,468] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,654] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,655] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:36,719] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:36,719] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,042] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,043] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,081] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,082] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,142] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,143] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,165] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,166] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,490] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,491] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,589] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,590] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:37,720] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:37,721] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,008] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,009] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,047] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,048] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,144] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,145] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,170] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,170] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,439] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,440] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,513] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,513] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:38,725] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:38,726] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:39,041] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:39,042] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:39,049] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:39,050] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:39,147] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:39,148] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:39,176] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:39,176] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:39,437] ERROR [Producer clientId=connect-cluster-statuses] Interrupted while joining ioThread (org.apache.kafka.clients.producer.KafkaProducer:1398)
java.lang.InterruptedException
	at java.base/java.lang.Object.wait0(Native Method)
	at java.base/java.lang.Object.wait(Object.java:366)
	at java.base/java.lang.Thread.join(Thread.java:2073)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1395)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1366)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1342)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1117)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1100)
	at org.apache.kafka.connect.util.KafkaBasedLog.lambda$stop$4(KafkaBasedLog.java:334)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:334)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:222)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:175)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:816)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:809)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:385)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:11:39,439] INFO [Producer clientId=connect-cluster-statuses] Proceeding to force close the producer since pending requests could not be completed within timeout 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1407)
[2025-03-22 16:11:39,443] ERROR Failed to write status update (org.apache.kafka.connect.storage.KafkaStatusBackingStore:319)
org.apache.kafka.common.KafkaException: Producer is closed forcefully.
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:1128)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:1115)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:298)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:11:39,443] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,444] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,444] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,445] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,443] ERROR Failed to write status update (org.apache.kafka.connect.storage.KafkaStatusBackingStore:319)
org.apache.kafka.common.KafkaException: Producer is closed forcefully.
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:1128)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:1115)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:298)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:11:39,445] ERROR Failed to write status update (org.apache.kafka.connect.storage.KafkaStatusBackingStore:319)
org.apache.kafka.common.KafkaException: Producer is closed forcefully.
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:1128)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:1115)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:298)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:11:39,445] ERROR Failed to write status update (org.apache.kafka.connect.storage.KafkaStatusBackingStore:319)
org.apache.kafka.common.KafkaException: Producer is closed forcefully.
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:1128)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:1115)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:298)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 16:11:39,446] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,446] WARN Failed to close KafkaBasedLog producer for topic connect-status with type org.apache.kafka.clients.producer.KafkaProducer (org.apache.kafka.common.utils.Utils:1119)
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1397)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1366)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1342)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1117)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1100)
	at org.apache.kafka.connect.util.KafkaBasedLog.lambda$stop$4(KafkaBasedLog.java:334)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:334)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:222)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:175)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:816)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:809)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:385)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.InterruptedException
	at java.base/java.lang.Object.wait0(Native Method)
	at java.base/java.lang.Object.wait(Object.java:366)
	at java.base/java.lang.Thread.join(Thread.java:2073)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1395)
	... 17 more
[2025-03-22 16:11:39,453] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 16:11:39,453] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 16:11:39,457] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:11:39,458] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (srv-ubuntu/127.0.1.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-03-22 16:11:39,459] ERROR [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Failed to close fetcher with a timeout(ms)=29998 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:1052)
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeThrowInterruptException(ConsumerNetworkClient.java:536)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)
	at org.apache.kafka.clients.consumer.internals.Fetcher.maybeCloseFetchSessions(Fetcher.java:131)
	at org.apache.kafka.clients.consumer.internals.Fetcher.closeInternal(Fetcher.java:168)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.lambda$close$11(AbstractFetch.java:478)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:161)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:139)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.close(AbstractFetch.java:478)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.lambda$close$3(LegacyKafkaConsumer.java:1148)
	at org.apache.kafka.common.utils.Utils.swallow(Utils.java:1042)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.close(LegacyKafkaConsumer.java:1148)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.close(LegacyKafkaConsumer.java:1104)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.close(LegacyKafkaConsumer.java:1092)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1757)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1117)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1100)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:335)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:222)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:175)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:816)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:809)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:385)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.InterruptedException
	... 27 more
[2025-03-22 16:11:39,460] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,460] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,460] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,460] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,464] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,464] WARN Failed to close KafkaBasedLog consumer for topic connect-status with type org.apache.kafka.clients.consumer.KafkaConsumer (org.apache.kafka.common.utils.Utils:1119)
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeThrowInterruptException(ConsumerNetworkClient.java:536)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)
	at org.apache.kafka.clients.consumer.internals.Fetcher.maybeCloseFetchSessions(Fetcher.java:131)
	at org.apache.kafka.clients.consumer.internals.Fetcher.closeInternal(Fetcher.java:168)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.lambda$close$11(AbstractFetch.java:478)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:161)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:139)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.close(AbstractFetch.java:478)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.lambda$close$3(LegacyKafkaConsumer.java:1148)
	at org.apache.kafka.common.utils.Utils.swallow(Utils.java:1042)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.close(LegacyKafkaConsumer.java:1148)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.close(LegacyKafkaConsumer.java:1104)
	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.close(LegacyKafkaConsumer.java:1092)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1757)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1117)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1100)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:335)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:222)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:175)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:816)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:809)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:385)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.InterruptedException
	... 27 more
[2025-03-22 16:11:39,465] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 16:11:39,465] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 16:11:39,465] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 16:11:39,465] WARN Failed to close KafkaBasedLog for config topic with type org.apache.kafka.connect.storage.KafkaConfigBackingStore$$Lambda/0x0000000601647d78 (org.apache.kafka.common.utils.Utils:1119)
org.apache.kafka.connect.errors.ConnectException: Failed to stop KafkaBasedLog. Exiting without cleanly shutting down it's producer and consumer.
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:329)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1117)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1100)
	at org.apache.kafka.connect.storage.KafkaConfigBackingStore.stop(KafkaConfigBackingStore.java:408)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:176)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:816)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:809)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:385)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.InterruptedException
	at java.base/java.lang.Object.wait0(Native Method)
	at java.base/java.lang.Object.wait(Object.java:366)
	at java.base/java.lang.Thread.join(Thread.java:2079)
	at java.base/java.lang.Thread.join(Thread.java:2155)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:327)
	... 12 more
[2025-03-22 16:11:39,466] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 16:11:39,466] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 16:11:39,467] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 16:11:39,467] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 16:11:39,467] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 16:11:39,470] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,470] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,470] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,470] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,471] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,471] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 16:11:39,471] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 16:11:39,472] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,472] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,472] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,473] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,474] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,474] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 16:11:39,475] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 16:11:39,475] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,475] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,475] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,475] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,475] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 16:11:39,477] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 16:11:39,477] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,477] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,478] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,479] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,480] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:11:39,480] INFO [AdminClient clientId=connect-cluster-shared-admin] Metadata update failed (org.apache.kafka.clients.admin.internals.AdminMetadataManager:272)
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
[2025-03-22 16:11:39,480] INFO [AdminClient clientId=connect-cluster-shared-admin] Timed out 1 remaining operation(s) during close. (org.apache.kafka.clients.admin.KafkaAdminClient:1470)
[2025-03-22 16:11:39,481] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:11:39,481] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:11:39,481] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:11:39,481] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 16:11:39,483] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 16:11:39,483] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-03-22 16:21:35,078] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 16:21:35,080] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 16:21:35,081] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 16:21:35,093] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,198] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,204] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,209] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,209] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,216] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,300] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,303] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,303] INFO Scanning plugins with ServiceLoaderScanner took 211 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 16:21:35,305] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,332] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,333] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,347] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,347] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:35,608] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:35,613] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 16:21:36,165] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 16:21:36,166] INFO Scanning plugins with ReflectionScanner took 861 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 16:21:36,168] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,169] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,170] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,171] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,172] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,173] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,173] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,173] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,173] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,173] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,173] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 16:21:36,174] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,174] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,175] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,176] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,177] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 16:21:36,196] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 16:21:36,197] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 16:21:36,198] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 16:21:36,219] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 16:21:36,219] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,220] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,220] INFO Kafka startTimeMs: 1742660496219 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,323] INFO Kafka cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 16:21:36,323] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 16:21:36,326] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 16:21:36,326] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 16:21:36,326] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 16:21:36,329] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 16:21:36,333] INFO Logging initialized @1458ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 16:21:36,348] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 16:21:36,348] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 16:21:36,358] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 16:21:36,369] INFO Started http_8083@3d96b8fb{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 16:21:36,369] INFO Started @1494ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 16:21:36,380] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:21:36,380] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 16:21:36,380] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:21:36,380] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 16:21:36,380] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:21:36,380] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 16:21:36,382] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:21:36,392] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,392] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,392] INFO Kafka startTimeMs: 1742660496392 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,400] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:21:36,401] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:21:36,413] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 16:21:36,423] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,423] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,423] INFO Kafka startTimeMs: 1742660496423 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,425] INFO Kafka Connect worker initialization took 1346ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 16:21:36,425] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 16:21:36,426] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 16:21:36,426] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 16:21:36,426] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 16:21:36,427] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 16:21:36,427] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 16:21:36,427] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 16:21:36,428] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 16:21:36,429] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,429] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,429] INFO Kafka startTimeMs: 1742660496429 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,439] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 16:21:36,454] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 16:21:36,454] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 16:21:36,455] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 16:21:36,646] INFO Started o.e.j.s.ServletContextHandler@1cd853ee{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 16:21:36,646] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 16:21:36,646] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 16:21:36,753] INFO Created topic (name=connect-offsets, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:415)
[2025-03-22 16:21:36,757] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:21:36,766] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:21:36,774] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:21:36,774] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,774] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,774] INFO Kafka startTimeMs: 1742660496774 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,777] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:21:36,778] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:36,782] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:21:36,793] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:21:36,793] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,793] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,793] INFO Kafka startTimeMs: 1742660496793 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,797] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:36,801] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,802] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,803] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,822] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,822] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,823] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,824] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,825] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,825] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 16:21:36,825] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 16:21:36,825] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 16:21:36,826] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 16:21:36,826] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 16:21:36,893] INFO Created topic (name=connect-status, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:415)
[2025-03-22 16:21:36,893] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:21:36,894] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:21:36,896] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:21:36,896] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,896] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,896] INFO Kafka startTimeMs: 1742660496896 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,896] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:21:36,896] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:21:36,898] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:21:36,898] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,898] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,898] INFO Kafka startTimeMs: 1742660496898 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,900] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:36,901] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:36,902] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 16:21:36,902] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,902] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,902] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,902] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,902] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,907] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,907] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,907] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,907] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,907] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,907] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 16:21:36,907] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 16:21:36,909] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 16:21:36,909] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 16:21:36,932] INFO Created topic (name=connect-configs, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:415)
[2025-03-22 16:21:36,932] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:21:36,932] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:21:36,934] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:21:36,934] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,934] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,934] INFO Kafka startTimeMs: 1742660496934 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,934] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:21:36,934] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:21:36,936] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:21:36,936] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:21:36,936] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:21:36,936] INFO Kafka startTimeMs: 1742660496936 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:21:36,938] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:36,938] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 16:21:36,938] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 16:21:36,938] INFO [Producer clientId=connect-cluster-configs] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:36,944] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:21:36,944] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 16:21:36,944] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 16:21:36,944] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 16:21:36,944] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 16:21:36,949] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:21:37,247] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 16:21:37,248] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:21:37,249] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:21:37,256] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:21:37,261] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:21:37,281] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:21:37,281] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', leaderUrl='http://127.0.1.1:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:21:37,281] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:21:37,281] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:21:37,318] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2483)
[2025-03-22 16:21:46,205] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:16:21:46 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "curl/8.5.0" 32 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 16:22:18,426] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 16:22:18,432] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector bluesky-apartado-2-generative-ai config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-03-22 16:22:18,433] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:22:18,433] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:22:18,435] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:22:18,439] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:22:18,439] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', leaderUrl='http://127.0.1.1:8083/', offset=2, connectorIds=[bluesky-apartado-2-generative-ai], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:22:18,440] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:22:18,440] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 16:22:18,440] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:16:22:18 +0000] "POST /connectors HTTP/1.1" 201 1525 "-" "curl/8.5.0" 55 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 16:22:18,441] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 16:22:18,442] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:22:18,442] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:18,444] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 16:22:18,445] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 16:22:18,445] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:22:18,445] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 16:22:18,449] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:22:18,450] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:18,461] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Tasks [bluesky-apartado-2-generative-ai-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-03-22 16:22:18,462] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:22:18,462] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:22:18,463] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:22:18,465] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:22:18,465] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', leaderUrl='http://127.0.1.1:8083/', offset=4, connectorIds=[bluesky-apartado-2-generative-ai], taskIds=[bluesky-apartado-2-generative-ai-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:22:18,466] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:22:18,466] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 16:22:18,468] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 16:22:18,468] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 16:22:18,469] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 16:22:18,470] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 16:22:18,472] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 16:22:18,473] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 16:22:18,473] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:18,474] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 16:22:18,474] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:22:18,476] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 16:22:18,476] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:22:18,476] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:22:18,476] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742660538476 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:22:18,478] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:22:18,480] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 16:22:18,480] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:22:18,480] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 16:22:18,486] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 16:22:18,567] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 16:22:20,346] INFO [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 16:22:25,346] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset null (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:22:26,362] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:17:37.183Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:22:26,636] WARN [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Error while fetching metadata with correlation id 4 : {bluesky_apartado_2=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1213)
[2025-03-22 16:22:28,481] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 100 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:22:34,819] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 16:22:34,823] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector mysql-sink-bluesky config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-03-22 16:22:34,824] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:22:34,824] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:22:34,825] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:16:22:34 +0000] "POST /connectors HTTP/1.1" 201 768 "-" "curl/8.5.0" 18 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 16:22:34,825] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:22:34,827] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:22:34,827] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', leaderUrl='http://127.0.1.1:8083/', offset=5, connectorIds=[mysql-sink-bluesky, bluesky-apartado-2-generative-ai], taskIds=[bluesky-apartado-2-generative-ai-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:22:34,827] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 5 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:22:34,827] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 16:22:34,827] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 16:22:34,828] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 16:22:34,829] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:34,829] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.2 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 16:22:34,829] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 16:22:34,829] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:22:34,831] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 16:22:34,831] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:34,831] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-22 16:22:34,843] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Tasks [mysql-sink-bluesky-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-03-22 16:22:34,843] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 16:22:34,844] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 16:22:34,845] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 16:22:34,847] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 16:22:34,847] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-c7db9998-47d0-4897-bac0-cc30e1238c92', leaderUrl='http://127.0.1.1:8083/', offset=7, connectorIds=[mysql-sink-bluesky, bluesky-apartado-2-generative-ai], taskIds=[mysql-sink-bluesky-0, bluesky-apartado-2-generative-ai-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 16:22:34,847] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 16:22:34,848] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 16:22:34,851] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 16:22:34,852] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 16:22:34,852] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.2 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 16:22:34,853] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 16:22:34,854] WARN [mysql-sink-bluesky|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:113)
[2025-03-22 16:22:34,854] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 16:22:34,854] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 16:22:34,855] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 16:22:34,855] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 16:22:34,855] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 16:22:34,857] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 16:22:34,857] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 16:22:34,857] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 16:22:34,857] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742660554857 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 16:22:34,859] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 16:22:34,859] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_apartado_2 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-22 16:22:34,859] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-22 16:22:34,860] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/bluesky_db
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-22 16:22:34,860] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-22 16:22:34,860] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 16:22:34,860] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 16:22:34,861] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 16:22:34,861] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 16:22:34,862] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-22 16:22:34,862] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-22 16:22:34,862] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-22 16:22:34,863] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-22 16:22:34,865] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: HNovrBq-RnqW7P9hlfUWvQ (org.apache.kafka.clients.Metadata:364)
[2025-03-22 16:22:34,866] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-22 16:22:34,866] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 16:22:34,870] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-542f6165-1a21-4640-8b34-f3cc2a182e3f (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 16:22:34,870] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 16:22:34,873] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-542f6165-1a21-4640-8b34-f3cc2a182e3f', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-22 16:22:34,875] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-bluesky-0-542f6165-1a21-4640-8b34-f3cc2a182e3f=Assignment(partitions=[bluesky_apartado_2-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-22 16:22:34,877] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-542f6165-1a21-4640-8b34-f3cc2a182e3f', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-22 16:22:34,877] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_apartado_2-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-22 16:22:34,878] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-22 16:22:34,883] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-22 16:22:34,886] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_apartado_2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 16:22:35,001] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-22 16:22:35,002] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:22:35,015] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "bluesky_db"."bluesky_apartado_2" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-22 16:22:35,026] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "bluesky_db"."bluesky_apartado_2" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-22 16:22:35,027] INFO [mysql-sink-bluesky|task-0] Creating table with sql: CREATE TABLE `bluesky_db`.`bluesky_apartado_2` (
`uri` TEXT NOT NULL,
`cid` TEXT NOT NULL,
`text` TEXT NOT NULL,
`createdAt` DATETIME(3) NULL,
`handle` TEXT NOT NULL,
`displayName` TEXT NULL,
`avatar` TEXT NULL) (io.confluent.connect.jdbc.sink.DbStructure:122)
[2025-03-22 16:22:35,044] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "bluesky_db"."bluesky_apartado_2" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-22 16:22:35,046] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "bluesky_db"."bluesky_apartado_2" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-22 16:22:35,052] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "bluesky_db"."bluesky_apartado_2" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-22 16:22:35,053] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "bluesky_db"."bluesky_apartado_2" to Table{name='"bluesky_db"."bluesky_apartado_2"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=true, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-22 16:22:35,102] INFO [mysql-sink-bluesky|task-0] Completed write operation for 100 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:22:35,102] INFO [mysql-sink-bluesky|task-0] Successfully wrote 100 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:23:23,092] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:16:23:23 +0000] "GET /connectors HTTP/1.1" 200 57 "-" "curl/8.5.0" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 16:23:25,349] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:17:37.183Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:24:25,349] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:17:37.183Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:25:25,349] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:17:37.183Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:26:25,351] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:17:37.183Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:26:36,533] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:27:25,352] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:17:37.183Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:27:26,017] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:26:52.159Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:27:26,280] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:27:26,286] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:27:26,287] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:27:28,512] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:28:25,353] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:26:52.159Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:29:25,353] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:26:52.159Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:30:25,353] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:26:52.159Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:30:36,948] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:30:36,993] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:30:37,050] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:30:37,050] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:30:37,087] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:30:37,109] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:30:58,686] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:31:25,354] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:26:52.159Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:31:25,981] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:30:29.330Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:31:26,287] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:31:26,291] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:31:26,297] INFO [mysql-sink-bluesky|task-0] Completed write operation for 2 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:31:26,297] INFO [mysql-sink-bluesky|task-0] Successfully wrote 2 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:31:28,544] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 2 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:31:34,939] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:31:36,629] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:32:25,354] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:30:29.330Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:33:25,358] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:30:29.330Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:34:25,361] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:30:29.330Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:34:25,650] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:34:09.442Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:34:25,900] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:34:25,905] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:34:25,905] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:34:28,564] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:35:25,361] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:34:09.442Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:36:25,361] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:34:09.442Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:36:36,830] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:37:25,361] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:34:09.442Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:37:26,148] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:36:28.589Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:37:26,398] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:37:26,404] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:37:26,404] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:37:28,593] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:38:25,362] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:36:28.589Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:39:25,363] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:36:28.589Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:40:25,363] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:36:28.589Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:40:36,934] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:40:37,007] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:40:37,213] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:41:25,365] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:36:28.589Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:41:37,034] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:42:25,365] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:36:28.589Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:42:25,737] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:41:23.117Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:42:25,974] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:42:25,979] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:42:25,979] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:42:28,628] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:43:25,365] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:41:23.117Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:44:25,365] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:41:23.117Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:45:25,365] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:41:23.117Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:46:25,367] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:41:23.117Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:46:37,237] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:47:25,368] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:41:23.117Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:47:25,953] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:46:24.862Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:47:26,195] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:47:26,201] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:47:26,201] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:47:28,665] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:48:25,370] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:46:24.862Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:49:25,371] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:46:24.862Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:50:25,371] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:46:24.862Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:51:25,372] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:46:24.862Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:51:37,437] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:52:25,375] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:46:24.862Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:52:25,629] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:51:53Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:52:25,878] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:52:25,884] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:52:25,884] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:52:25,885] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:52:25,889] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:52:25,889] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:52:28,696] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 2 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:53:25,375] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:51:53Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:54:25,375] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:51:53Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:55:25,376] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:51:53Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:56:25,381] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:51:53Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:56:25,642] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:55:58.710Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:56:25,892] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 16:56:25,897] INFO [mysql-sink-bluesky|task-0] Completed write operation for 1 records to the database (io.confluent.connect.jdbc.sink.JdbcDbWriter:100)
[2025-03-22 16:56:25,897] INFO [mysql-sink-bluesky|task-0] Successfully wrote 1 records. (io.confluent.connect.jdbc.sink.JdbcSinkTask:91)
[2025-03-22 16:56:28,726] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 16:56:37,639] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 16:57:25,386] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:55:58.710Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:58:25,386] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:55:58.710Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 16:59:25,386] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T16:55:58.710Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
