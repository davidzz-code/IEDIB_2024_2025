[2025-03-22 15:01:25,733] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:06:25,892] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:10:28,955] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 15:10:28,955] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 15:10:28,962] INFO Stopped http_8083@6a233d33{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 15:10:28,962] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 15:10:28,969] INFO Stopped o.e.j.s.ServletContextHandler@2a41d17a{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 15:10:28,969] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 15:10:28,969] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 15:10:28,969] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 15:10:28,969] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:10:28,969] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:10:28,970] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:10:28,970] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:10:28,970] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:10:28,970] INFO [mysql-sink-bluesky|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:10:28,970] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 15:10:28,972] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:10:28,972] INFO [mysql-sink-bluesky|worker] Completed shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:10:28,972] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:10:28,974] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:10:28,974] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:10:28,975] INFO [mysql-sink-bluesky|task-0] Stopping task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:10:28,975] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 15:10:28,975] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:10:28,977] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:28,978] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:28,978] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:28,978] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:28,978] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,009] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:10:29,011] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,011] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,011] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,011] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,011] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,013] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:10:29,013] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:10:29,014] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,015] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,015] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,015] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,015] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,015] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:10:29,015] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:10:29,016] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 sent an invalid full fetch response with extraIds=(LmGjEukESoSMrPpq-3XYTQ), response=() (org.apache.kafka.clients.FetchSessionHandler:555)
[2025-03-22 15:10:29,016] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,017] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,017] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,017] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,018] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,018] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:10:29,018] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 15:10:29,018] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:10:29,019] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:10:29,020] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,020] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,020] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,020] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,020] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,020] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:10:29,020] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:10:29,323] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,324] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,324] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,326] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,331] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,332] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:10:29,332] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 15:10:29,332] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 15:10:29,335] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 15:10:29,336] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:10:29,337] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:10:29,341] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,342] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,342] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,342] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,342] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,343] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:10:29,343] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:10:29,556] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,556] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,558] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,559] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,566] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,567] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:10:29,567] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 15:10:29,567] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,568] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,568] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,568] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,569] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 15:10:29,573] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1173)
[2025-03-22 15:10:29,574] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 15:10:29,574] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-03-22 15:10:29,574] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,574] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,575] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,577] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,579] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:29,581] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:29,581] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:29,581] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:29,582] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 15:10:29,583] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 15:10:29,584] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-03-22 15:10:35,266] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 15:10:35,268] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 15:10:35,269] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 15:10:35,279] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,372] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,375] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,379] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,379] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,386] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,453] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,456] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,456] INFO Scanning plugins with ServiceLoaderScanner took 178 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:10:35,457] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,478] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,478] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,494] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,494] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:35,758] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:35,763] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:10:36,283] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:10:36,283] INFO Scanning plugins with ReflectionScanner took 826 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:10:36,284] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,285] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,286] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,287] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,288] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:10:36,289] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,289] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,290] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,291] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,292] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:10:36,306] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 15:10:36,306] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 15:10:36,307] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:10:36,330] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:10:36,333] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,333] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,333] INFO Kafka startTimeMs: 1742656236330 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,430] INFO Kafka cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 15:10:36,430] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:36,432] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:36,433] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:36,433] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:36,435] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 15:10:36,439] INFO Logging initialized @1384ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 15:10:36,452] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 15:10:36,453] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 15:10:36,462] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 15:10:36,473] INFO Started http_8083@21ed4a51{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 15:10:36,473] INFO Started @1418ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 15:10:36,482] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:10:36,482] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 15:10:36,482] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:10:36,482] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 15:10:36,482] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:10:36,483] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 15:10:36,485] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,496] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,497] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,497] INFO Kafka startTimeMs: 1742656236496 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,501] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,502] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,509] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:10:36,520] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,520] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,520] INFO Kafka startTimeMs: 1742656236520 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,521] INFO Kafka Connect worker initialization took 1254ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 15:10:36,521] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 15:10:36,522] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 15:10:36,522] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 15:10:36,523] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 15:10:36,523] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 15:10:36,523] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:10:36,523] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:10:36,525] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:10:36,525] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,525] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,525] INFO Kafka startTimeMs: 1742656236525 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,535] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 15:10:36,547] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:10:36,552] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 15:10:36,552] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 15:10:36,552] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 15:10:36,556] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,565] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:10:36,565] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,565] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,565] INFO Kafka startTimeMs: 1742656236565 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,568] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:10:36,568] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,573] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,588] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:10:36,588] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,589] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,589] INFO Kafka startTimeMs: 1742656236588 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,592] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,595] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,596] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,597] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,612] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,612] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,612] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,612] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,612] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,612] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,613] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,615] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,615] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,644] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:10:36,644] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:10:36,644] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 15:10:36,645] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 15:10:36,645] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:10:36,649] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:10:36,652] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,653] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:10:36,654] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,654] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,655] INFO Kafka startTimeMs: 1742656236654 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,655] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:10:36,656] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,658] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:10:36,658] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,658] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,658] INFO Kafka startTimeMs: 1742656236658 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,659] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,660] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,661] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:10:36,661] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,661] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,661] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,662] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,662] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,667] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,668] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,668] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,668] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,668] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,676] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:10:36,676] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:10:36,677] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 15:10:36,678] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:10:36,685] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:10:36,686] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,687] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:10:36,687] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,687] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,687] INFO Kafka startTimeMs: 1742656236687 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,688] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:10:36,690] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,691] INFO [Producer clientId=connect-cluster-configs] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,693] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:10:36,693] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,693] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,693] INFO Kafka startTimeMs: 1742656236693 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,694] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,695] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:10:36,695] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:10:36,702] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,706] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:10:36,706] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:10:36,706] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:10:36,707] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:10:36,707] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:10:36,707] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 15:10:36,707] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 15:10:36,711] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,711] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 15:10:36,713] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 15:10:36,713] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:10:36,717] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:10:36,720] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-127.0.1.1:8083-2ba74a18-3636-494e-99a1-dc9976272f27', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 15:10:36,728] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-127.0.1.1:8083-2ba74a18-3636-494e-99a1-dc9976272f27', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 15:10:36,728] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-2ba74a18-3636-494e-99a1-dc9976272f27', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed, mysql-sink-bluesky], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0, mysql-sink-bluesky-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 15:10:36,729] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-22 15:10:36,729] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 32, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-22 15:10:36,730] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-22 15:10:36,730] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 15:10:36,731] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:10:36,731] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:10:36,732] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:10:36,732] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:10:36,734] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:10:36,735] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:10:36,735] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:10:36,735] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:10:36,736] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:10:36,736] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:10:36,736] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:10:36,737] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:10:36,737] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:10:36,738] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:10:36,738] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:10:36,738] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:10:36,738] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,738] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,739] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:10:36,739] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:10:36,739] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,739] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-22 15:10:36,740] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,740] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-22 15:10:36,740] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.2 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:10:36,740] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:10:36,740] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,741] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:10:36,742] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:10:36,742] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,742] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:10:36,743] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:10:36,743] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:10:36,743] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,743] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,743] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,744] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:10:36,744] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:10:36,744] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:10:36,746] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:10:36,746] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:10:36,746] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.2 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:10:36,746] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,747] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:10:36,747] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:10:36,747] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:10:36,747] INFO Started o.e.j.s.ServletContextHandler@515fff35{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 15:10:36,747] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 15:10:36,747] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 15:10:36,747] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:10:36,748] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:10:36,748] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,747] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:10:36,748] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:10:36,749] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:10:36,749] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:10:36,749] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:10:36,750] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:10:36,750] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:10:36,750] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,747] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:10:36,750] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:10:36,750] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:10:36,750] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,751] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,751] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:10:36,751] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,751] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,751] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742656236751 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,751] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:10:36,751] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:10:36,752] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:10:36,756] INFO [file-source-distributed|worker] Starting file source connector reading from /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-22 15:10:36,755] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:10:36,756] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,756] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,756] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742656236756 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,755] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 15:10:36,754] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:10:36,753] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:10:36,756] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,759] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,760] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 15:10:36,759] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:10:36,760] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:10:36,759] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:10:36,761] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:10:36,761] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:10:36,761] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742656236761 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:10:36,762] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:10:36,763] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 15:10:36,763] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_apartado_2 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-22 15:10:36,764] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-22 15:10:36,766] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:10:36,767] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 15:10:36,767] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,767] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-22 15:10:36,769] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:10:36,769] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,769] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:10:36,770] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:10:36,776] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/bluesky_db
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = generative_ai_posts
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-22 15:10:36,777] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-22 15:10:36,777] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:10:36,777] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:10:36,778] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:10:36,778] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:10:36,779] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-22 15:10:36,779] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-22 15:10:36,779] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-22 15:10:36,780] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-22 15:10:36,786] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:10:36,786] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-22 15:10:36,787] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:10:36,793] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-b5a5a923-f182-4b8c-856a-1874f13d1530 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:10:36,793] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:10:36,794] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-b5a5a923-f182-4b8c-856a-1874f13d1530', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-22 15:10:36,797] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-bluesky-0-b5a5a923-f182-4b8c-856a-1874f13d1530=Assignment(partitions=[bluesky_apartado_2-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-22 15:10:36,799] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-b5a5a923-f182-4b8c-856a-1874f13d1530', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-22 15:10:36,800] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_apartado_2-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-22 15:10:36,800] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-22 15:10:36,802] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-22 15:10:36,805] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_apartado_2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:10:36,845] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 15:10:36,933] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-22 15:10:36,933] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 15:10:36,945] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:10:36,947] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
[2025-03-22 15:10:36,947] INFO [mysql-sink-bluesky|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:178)
[2025-03-22 15:10:36,949] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Revoke previously assigned partitions bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-03-22 15:10:36,949] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Member connector-consumer-mysql-sink-bluesky-0-b5a5a923-f182-4b8c-856a-1874f13d1530 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-03-22 15:10:36,949] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:10:36,949] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:10:37,317] INFO [mysql-sink-bluesky|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:10:37,318] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:37,319] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:10:37,319] INFO [mysql-sink-bluesky|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:10:37,329] INFO [mysql-sink-bluesky|task-0] App info kafka.consumer for connector-consumer-mysql-sink-bluesky-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:10:37,922] INFO [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:10:42,922] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T12:30:12.785Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:10:43,477] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:10:46,760] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 20 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 15:11:42,922] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:12:42,922] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:13:42,922] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:14:42,922] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:15:36,624] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:15:42,924] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:16:42,924] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:17:42,924] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:18:42,925] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:19:36,622] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:36,785] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:36,793] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:36,887] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:36,927] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:36,945] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:37,000] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:37,023] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:37,160] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:19:42,930] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:20:36,731] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:20:42,931] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:20:47,366] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 15:20:47,366] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 15:20:47,370] INFO Stopped http_8083@21ed4a51{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 15:20:47,370] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 15:20:47,373] INFO Stopped o.e.j.s.ServletContextHandler@515fff35{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 15:20:47,373] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 15:20:47,373] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 15:20:47,373] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 15:20:47,373] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:20:47,373] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:20:47,374] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:20:47,374] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:20:47,374] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:20:47,374] INFO [mysql-sink-bluesky|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:20:47,374] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 15:20:47,376] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:20:47,376] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:20:47,376] INFO [mysql-sink-bluesky|worker] Completed shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:20:47,377] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:20:47,377] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:20:47,377] INFO [mysql-sink-bluesky|task-0] Stopping task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:20:47,377] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 15:20:47,378] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:20:47,380] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:47,380] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,380] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,380] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:47,380] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:47,457] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:20:47,459] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:47,460] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,460] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,460] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:47,460] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:47,462] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:20:47,462] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:20:47,463] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:47,464] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,464] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,464] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:47,464] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:47,464] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:20:47,464] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:20:47,969] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:47,970] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,971] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,971] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:47,978] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:47,979] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:20:47,979] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 15:20:47,980] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:20:47,981] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:20:47,986] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:47,986] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,987] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:47,987] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:47,987] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:47,988] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:20:47,988] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:20:48,191] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:48,192] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,194] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,195] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:48,199] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:48,199] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:20:48,199] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 15:20:48,200] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 15:20:48,202] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 15:20:48,202] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:20:48,203] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:20:48,207] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:48,208] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,208] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,208] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:48,208] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:48,209] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:20:48,209] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:20:48,290] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:48,291] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,292] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,292] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:48,297] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:48,297] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:20:48,297] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 15:20:48,298] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:48,298] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,298] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:48,298] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:48,299] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 15:20:48,304] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-2ba74a18-3636-494e-99a1-dc9976272f27 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1173)
[2025-03-22 15:20:48,305] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 15:20:48,305] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-03-22 15:20:48,305] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:48,305] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,305] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:48,308] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:48,312] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:48,314] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:48,315] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:48,315] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:48,316] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 15:20:48,318] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 15:20:48,318] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-03-22 15:20:54,125] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 15:20:54,127] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 15:20:54,127] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 15:20:54,137] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,229] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,232] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,236] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,236] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,242] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,306] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,309] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,309] INFO Scanning plugins with ServiceLoaderScanner took 172 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:20:54,310] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,331] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,332] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,347] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,347] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:54,597] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:54,602] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:20:55,121] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:20:55,121] INFO Scanning plugins with ReflectionScanner took 811 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:20:55,123] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 15:20:55,123] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,123] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,124] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,125] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,126] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:20:55,127] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,127] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,127] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,127] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,127] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,127] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,127] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,128] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,129] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:20:55,143] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 15:20:55,143] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 15:20:55,145] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:20:55,166] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:20:55,166] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,166] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,167] INFO Kafka startTimeMs: 1742656855166 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,263] INFO Kafka cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 15:20:55,264] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:55,265] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:55,266] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:55,266] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:55,269] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 15:20:55,273] INFO Logging initialized @1356ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 15:20:55,286] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 15:20:55,286] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 15:20:55,295] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 15:20:55,305] INFO Started http_8083@6a97517{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 15:20:55,305] INFO Started @1389ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 15:20:55,316] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:20:55,316] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 15:20:55,316] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:20:55,316] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 15:20:55,316] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:20:55,316] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 15:20:55,318] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,328] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,329] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,329] INFO Kafka startTimeMs: 1742656855328 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,331] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,331] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,339] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:20:55,352] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,352] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,352] INFO Kafka startTimeMs: 1742656855352 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,354] INFO Kafka Connect worker initialization took 1228ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 15:20:55,354] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 15:20:55,355] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 15:20:55,355] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 15:20:55,357] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 15:20:55,357] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 15:20:55,357] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:20:55,358] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:20:55,359] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:20:55,359] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,359] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,359] INFO Kafka startTimeMs: 1742656855359 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,368] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 15:20:55,376] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:20:55,384] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 15:20:55,384] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 15:20:55,385] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 15:20:55,386] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,397] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:20:55,397] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,397] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,397] INFO Kafka startTimeMs: 1742656855397 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,400] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,403] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:20:55,408] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,421] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:20:55,421] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,421] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,421] INFO Kafka startTimeMs: 1742656855421 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,425] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,427] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:20:55,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,430] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,445] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,446] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,475] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:20:55,475] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:20:55,475] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 15:20:55,476] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 15:20:55,476] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:20:55,480] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:20:55,482] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,483] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:20:55,484] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,484] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,484] INFO Kafka startTimeMs: 1742656855484 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,485] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:20:55,485] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,487] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:20:55,487] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,487] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,487] INFO Kafka startTimeMs: 1742656855487 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,488] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,489] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,490] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:20:55,490] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,490] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,490] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,490] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,490] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,493] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,494] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,494] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,494] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,494] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,502] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:20:55,502] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:20:55,503] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 15:20:55,503] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:20:55,508] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:20:55,510] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,517] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:20:55,518] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,518] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,518] INFO Kafka startTimeMs: 1742656855518 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,518] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:20:55,519] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,519] INFO [Producer clientId=connect-cluster-configs] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,520] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:20:55,520] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,521] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,521] INFO Kafka startTimeMs: 1742656855520 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,522] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,522] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:20:55,523] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:20:55,526] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,529] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:20:55,530] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:20:55,530] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:20:55,531] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:20:55,531] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:20:55,531] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 15:20:55,531] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 15:20:55,534] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,535] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 15:20:55,536] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 15:20:55,536] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:20:55,539] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:20:55,541] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=9, memberId='connect-127.0.1.1:8083-c953eed3-b5ac-4942-9532-67acea7c1161', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 15:20:55,548] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=9, memberId='connect-127.0.1.1:8083-c953eed3-b5ac-4942-9532-67acea7c1161', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 15:20:55,549] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 9 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-c953eed3-b5ac-4942-9532-67acea7c1161', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed, mysql-sink-bluesky], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0, mysql-sink-bluesky-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 15:20:55,549] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-22 15:20:55,549] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 32, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-22 15:20:55,551] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-22 15:20:55,551] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 15:20:55,551] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:20:55,552] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:20:55,552] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:20:55,552] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:20:55,553] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:20:55,554] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:20:55,554] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:20:55,552] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:20:55,555] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:20:55,553] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:20:55,556] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:20:55,556] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,555] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:20:55,555] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:20:55,555] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:20:55,558] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:20:55,555] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:20:55,559] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:20:55,559] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,559] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,560] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:20:55,560] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,557] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,561] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,561] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:20:55,561] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:20:55,561] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:20:55,562] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:20:55,562] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:20:55,562] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,562] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,562] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:20:55,562] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:20:55,562] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:20:55,562] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-22 15:20:55,562] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,562] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-22 15:20:55,563] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:20:55,563] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:20:55,563] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.2 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:20:55,563] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:20:55,564] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 15:20:55,564] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:20:55,565] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:20:55,565] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,565] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:20:55,565] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.2 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:20:55,565] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:20:55,565] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:20:55,566] INFO Started o.e.j.s.ServletContextHandler@58041b11{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 15:20:55,566] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:20:55,566] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:20:55,566] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,566] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:20:55,566] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:20:55,566] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,567] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:20:55,566] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 15:20:55,567] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 15:20:55,567] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:20:55,568] INFO [file-source-distributed|worker] Starting file source connector reading from /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-22 15:20:55,567] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:20:55,566] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:20:55,566] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:20:55,569] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:20:55,569] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:20:55,569] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:20:55,570] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:20:55,567] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,571] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,572] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:20:55,572] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,572] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,572] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742656855572 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,572] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:20:55,573] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:20:55,574] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:20:55,574] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:20:55,575] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,575] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,575] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742656855575 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,577] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:20:55,577] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:20:55,577] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742656855575 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:20:55,577] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,579] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:20:55,579] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:20:55,580] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,581] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 15:20:55,582] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:20:55,583] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 15:20:55,584] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_apartado_2 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-22 15:20:55,584] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-22 15:20:55,585] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:20:55,586] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,587] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 15:20:55,595] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/bluesky_db
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = generative_ai_posts
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-22 15:20:55,596] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-22 15:20:55,596] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:20:55,596] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:20:55,597] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:20:55,597] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:20:55,598] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-22 15:20:55,599] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-22 15:20:55,599] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-22 15:20:55,599] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-22 15:20:55,604] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:20:55,605] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-22 15:20:55,606] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:20:55,613] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-ef90d635-aeb7-4cf7-84b6-e6fe878d11ec (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:20:55,613] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:20:55,615] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-ef90d635-aeb7-4cf7-84b6-e6fe878d11ec', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-22 15:20:55,618] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-bluesky-0-ef90d635-aeb7-4cf7-84b6-e6fe878d11ec=Assignment(partitions=[bluesky_apartado_2-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-22 15:20:55,620] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-ef90d635-aeb7-4cf7-84b6-e6fe878d11ec', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-22 15:20:55,620] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_apartado_2-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-22 15:20:55,620] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-22 15:20:55,622] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-22 15:20:55,624] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_apartado_2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:20:55,663] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 15:20:55,697] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:20:55,698] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,699] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:20:55,700] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:20:55,700] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-22 15:20:55,754] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-22 15:20:55,754] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 15:20:55,764] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:20:55,766] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
[2025-03-22 15:20:55,766] INFO [mysql-sink-bluesky|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:178)
[2025-03-22 15:20:55,768] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Revoke previously assigned partitions bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-03-22 15:20:55,768] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Member connector-consumer-mysql-sink-bluesky-0-ef90d635-aeb7-4cf7-84b6-e6fe878d11ec sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-03-22 15:20:55,769] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:20:55,769] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:20:56,129] INFO [mysql-sink-bluesky|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:20:56,129] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:56,129] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:20:56,129] INFO [mysql-sink-bluesky|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:20:56,132] INFO [mysql-sink-bluesky|task-0] App info kafka.consumer for connector-consumer-mysql-sink-bluesky-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:20:56,237] INFO [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:21:01,237] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:22:01,237] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:09:03.303Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:22:01,806] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:21:10.729Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:22:05,582] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 15:23:01,238] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:21:10.729Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:24:01,240] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:21:10.729Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:25:55,457] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,614] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,614] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,626] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,690] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,726] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,793] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,800] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,896] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:29:55,924] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:30:55,557] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:35:55,725] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:39:30,806] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:30:12.467Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:39:55,503] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:40:55,928] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:43:52,855] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:33:00.647Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:45:00,388] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 15:45:00,388] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 15:45:00,394] INFO Stopped http_8083@6a97517{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 15:45:00,394] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 15:45:00,398] INFO Stopped o.e.j.s.ServletContextHandler@58041b11{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 15:45:00,398] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 15:45:00,399] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 15:45:00,399] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 15:45:00,399] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:45:00,399] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:45:00,399] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:45:00,399] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:45:00,399] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 15:45:00,399] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:45:00,400] INFO [mysql-sink-bluesky|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:45:00,401] INFO [mysql-sink-bluesky|worker] Completed shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:45:00,402] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:45:00,401] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:45:00,405] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:45:00,406] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:45:00,406] INFO [mysql-sink-bluesky|task-0] Stopping task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:45:00,406] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 15:45:00,406] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:45:00,409] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:00,409] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:00,409] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:00,409] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:00,409] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,312] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:45:01,326] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:01,327] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,327] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,328] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:01,331] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,340] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:45:01,342] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:45:01,345] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:01,345] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,345] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,346] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:01,346] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,346] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:45:01,347] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:45:01,349] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 sent an invalid full fetch response with extraIds=(LmGjEukESoSMrPpq-3XYTQ), response=() (org.apache.kafka.clients.FetchSessionHandler:555)
[2025-03-22 15:45:01,350] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:01,350] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,350] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,350] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:01,352] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,352] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:45:01,352] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 15:45:01,353] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:45:01,354] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:45:01,356] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:01,356] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,356] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,357] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:01,357] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,357] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:45:01,357] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:45:01,745] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:01,747] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,747] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,751] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:01,756] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,757] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:45:01,757] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 15:45:01,757] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 15:45:01,762] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 15:45:01,762] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:45:01,763] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:45:01,770] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:01,771] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,771] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:01,771] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:01,772] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:01,772] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:45:01,773] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:45:02,157] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:02,158] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:02,159] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:02,161] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:02,167] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:02,167] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:45:02,167] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 15:45:02,168] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:02,168] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:02,168] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:02,168] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:02,168] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 15:45:02,173] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-c953eed3-b5ac-4942-9532-67acea7c1161 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1173)
[2025-03-22 15:45:02,174] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 15:45:02,175] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-03-22 15:45:02,175] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:02,175] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:02,175] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:02,178] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:02,181] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:02,182] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:02,183] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:02,183] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:02,183] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 15:45:02,184] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 15:45:02,185] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-03-22 15:45:08,461] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 15:45:08,463] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 15:45:08,463] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 15:45:08,473] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,567] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,569] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,573] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,573] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,580] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,649] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,652] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,652] INFO Scanning plugins with ServiceLoaderScanner took 179 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:45:08,652] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,674] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,674] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,690] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,690] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:08,961] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:08,966] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:45:09,479] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:45:09,480] INFO Scanning plugins with ReflectionScanner took 828 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:45:09,481] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,482] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,483] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,484] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,485] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,485] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,485] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:45:09,486] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,486] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,487] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,488] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:45:09,503] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 15:45:09,504] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 15:45:09,505] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:45:09,528] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:45:09,528] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,528] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,528] INFO Kafka startTimeMs: 1742658309528 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,632] INFO Kafka cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 15:45:09,632] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:45:09,634] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:09,634] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:09,635] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:09,637] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 15:45:09,641] INFO Logging initialized @1407ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 15:45:09,656] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 15:45:09,656] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 15:45:09,667] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 15:45:09,677] INFO Started http_8083@4713b631{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 15:45:09,677] INFO Started @1442ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 15:45:09,687] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:45:09,687] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 15:45:09,687] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:45:09,687] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 15:45:09,687] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:45:09,688] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 15:45:09,692] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,701] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,701] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,701] INFO Kafka startTimeMs: 1742658309701 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,704] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,704] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,711] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:45:09,722] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,722] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,722] INFO Kafka startTimeMs: 1742658309722 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,724] INFO Kafka Connect worker initialization took 1262ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 15:45:09,724] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 15:45:09,725] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 15:45:09,725] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 15:45:09,726] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 15:45:09,726] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 15:45:09,726] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:45:09,726] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:45:09,728] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:45:09,728] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,728] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,728] INFO Kafka startTimeMs: 1742658309728 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,738] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 15:45:09,749] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:45:09,755] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 15:45:09,755] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 15:45:09,756] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 15:45:09,759] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,767] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:45:09,768] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,768] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,768] INFO Kafka startTimeMs: 1742658309768 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,771] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:45:09,771] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,775] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,788] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:45:09,788] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,788] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,788] INFO Kafka startTimeMs: 1742658309788 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,791] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,793] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,795] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,809] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,809] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,809] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,809] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,810] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,837] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:45:09,837] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:45:09,837] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 15:45:09,837] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 15:45:09,838] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:45:09,842] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:45:09,843] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,845] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:45:09,845] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,845] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,845] INFO Kafka startTimeMs: 1742658309845 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,846] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:45:09,846] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,848] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,849] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:45:09,849] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,849] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,849] INFO Kafka startTimeMs: 1742658309849 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,851] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,852] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:45:09,852] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,852] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,852] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,852] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,852] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,855] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,855] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,855] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,855] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,855] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,864] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:45:09,864] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:45:09,865] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 15:45:09,865] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:45:09,871] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:45:09,871] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,873] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:45:09,873] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,873] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,873] INFO Kafka startTimeMs: 1742658309873 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,873] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:45:09,874] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,876] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:45:09,876] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,876] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,876] INFO Kafka startTimeMs: 1742658309876 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,878] INFO [Producer clientId=connect-cluster-configs] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,880] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,880] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:45:09,880] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:45:09,884] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:09,887] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:45:09,888] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:45:09,888] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:45:09,889] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:45:09,889] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:45:09,889] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 15:45:09,889] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 15:45:09,893] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,893] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 15:45:09,894] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 15:45:09,894] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:45:09,899] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:45:09,900] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=11, memberId='connect-127.0.1.1:8083-7412cba0-22b5-4658-977d-2f10536b3df1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 15:45:09,908] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=11, memberId='connect-127.0.1.1:8083-7412cba0-22b5-4658-977d-2f10536b3df1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 15:45:09,909] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-7412cba0-22b5-4658-977d-2f10536b3df1', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed, mysql-sink-bluesky], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0, mysql-sink-bluesky-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 15:45:09,909] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-22 15:45:09,909] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 32, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-22 15:45:09,911] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-22 15:45:09,911] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 15:45:09,913] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:45:09,913] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:45:09,913] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:45:09,914] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:45:09,915] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:45:09,917] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:45:09,917] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:45:09,917] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:45:09,917] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:45:09,917] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:45:09,917] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:45:09,918] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:45:09,918] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:45:09,918] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:45:09,919] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,919] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:45:09,919] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-22 15:45:09,920] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:45:09,921] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.2 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:45:09,921] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:45:09,919] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:45:09,921] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,922] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:45:09,922] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:45:09,919] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:45:09,924] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:45:09,919] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:45:09,925] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,919] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,926] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:45:09,926] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:45:09,927] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:45:09,927] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:45:09,925] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:45:09,925] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:45:09,927] INFO [file-source-distributed|worker] Starting file source connector reading from /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-22 15:45:09,925] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,927] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:45:09,922] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,929] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:45:09,927] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,929] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:45:09,929] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:45:09,927] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.2 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:45:09,930] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:45:09,930] INFO Started o.e.j.s.ServletContextHandler@a5d23c9{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 15:45:09,929] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 15:45:09,929] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:45:09,929] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,931] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 15:45:09,931] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 15:45:09,931] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:45:09,932] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:45:09,932] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:45:09,932] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:45:09,932] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:45:09,933] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:45:09,933] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:45:09,933] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,934] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:45:09,934] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:45:09,935] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:45:09,935] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,936] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,937] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:45:09,938] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:45:09,939] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:45:09,939] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,939] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,939] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742658309939 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,942] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,942] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:45:09,942] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,942] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,942] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742658309942 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,944] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:45:09,944] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:45:09,944] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:45:09,944] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742658309944 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:45:09,947] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:45:09,947] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:45:09,948] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_apartado_2 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-22 15:45:09,948] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-22 15:45:09,948] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,949] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 15:45:09,949] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:45:09,950] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 15:45:09,951] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:45:09,951] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,952] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:45:09,952] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:09,952] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-22 15:45:09,959] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 15:45:09,962] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/bluesky_db
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = generative_ai_posts
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-22 15:45:09,962] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-22 15:45:09,962] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:45:09,962] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:45:09,963] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:45:09,963] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:45:09,964] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-22 15:45:09,964] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-22 15:45:09,965] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-22 15:45:09,965] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-22 15:45:09,969] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:45:09,970] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-22 15:45:09,974] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:45:09,978] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-1a5a5fd4-1340-4d81-abd0-809f44b528b9 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:45:09,978] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:45:09,979] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-1a5a5fd4-1340-4d81-abd0-809f44b528b9', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-22 15:45:09,982] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-bluesky-0-1a5a5fd4-1340-4d81-abd0-809f44b528b9=Assignment(partitions=[bluesky_apartado_2-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-22 15:45:09,985] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-1a5a5fd4-1340-4d81-abd0-809f44b528b9', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-22 15:45:09,985] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_apartado_2-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-22 15:45:09,986] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-22 15:45:09,990] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-22 15:45:09,991] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_apartado_2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:45:10,025] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 15:45:10,031] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:45:10,032] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:45:10,252] INFO [mysql-sink-bluesky|task-0] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:837)
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:420)
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:238)
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:263)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:65)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:45:20,289] INFO [mysql-sink-bluesky|task-0] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:837)
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:420)
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:238)
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:263)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:65)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:45:30,323] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db' (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db'
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:65)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:837)
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:420)
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:238)
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:263)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 14 more
[2025-03-22 15:45:30,326] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db'
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:65)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLSyntaxErrorException: Unknown database 'bluesky_db'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:837)
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:420)
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:238)
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:263)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 14 more
[2025-03-22 15:45:30,327] INFO [mysql-sink-bluesky|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:178)
[2025-03-22 15:45:30,330] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Revoke previously assigned partitions bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-03-22 15:45:30,330] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Member connector-consumer-mysql-sink-bluesky-0-1a5a5fd4-1340-4d81-abd0-809f44b528b9 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-03-22 15:45:30,331] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:45:30,332] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:45:30,338] INFO [mysql-sink-bluesky|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:45:30,338] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:30,338] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:45:30,339] INFO [mysql-sink-bluesky|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:45:30,342] INFO [mysql-sink-bluesky|task-0] App info kafka.consumer for connector-consumer-mysql-sink-bluesky-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:12,508] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 15:47:12,510] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 15:47:12,522] INFO Stopped http_8083@4713b631{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 15:47:12,523] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 15:47:12,532] INFO Stopped o.e.j.s.ServletContextHandler@a5d23c9{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 15:47:12,533] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 15:47:12,533] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 15:47:12,533] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 15:47:12,533] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:47:12,534] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:47:12,534] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:47:12,534] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:47:12,534] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 15:47:12,534] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:47:12,535] INFO [mysql-sink-bluesky|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:47:12,535] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:47:12,535] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:47:12,535] INFO [mysql-sink-bluesky|worker] Completed shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:47:12,538] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:47:12,539] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:47:12,539] INFO [mysql-sink-bluesky|task-0] Stopping task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:47:13,162] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:47:13,177] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:13,178] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:13,180] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:13,180] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:13,182] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:17,540] ERROR [bluesky-apartado-2-generative-ai|task-0] Graceful stop of task bluesky-apartado-2-generative-ai-0 failed. (org.apache.kafka.connect.runtime.Worker:1074)
[2025-03-22 15:47:17,544] INFO [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 0 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:47:17,545] INFO [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms. (org.apache.kafka.clients.producer.KafkaProducer:1407)
[2025-03-22 15:47:17,555] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:47:17,557] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:17,557] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,557] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:47:17,558] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,559] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:17,563] INFO App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:17,567] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:17,567] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,568] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,568] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:17,568] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:17,569] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:47:17,569] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:47:17,730] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:17,730] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,731] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,731] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:17,735] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:17,736] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:47:17,736] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 15:47:17,737] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:47:17,738] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:47:17,742] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:17,742] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,742] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:17,742] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:17,742] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:17,742] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:47:17,743] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:47:18,162] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:18,163] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,164] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,164] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:18,171] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:18,172] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:47:18,172] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 15:47:18,172] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 15:47:18,176] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 15:47:18,176] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:47:18,177] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:47:18,182] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:18,182] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,182] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,182] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:18,183] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:18,184] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:47:18,184] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:47:18,670] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:18,670] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,672] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,672] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:18,679] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:18,680] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:47:18,680] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 15:47:18,680] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:18,680] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:18,680] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:18,681] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:18,681] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 15:47:19,697] ERROR [bluesky-apartado-2-generative-ai|task-0] Failure during login (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:141)
java.lang.InterruptedException
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:386)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at java.net.http/jdk.internal.net.http.HttpClientImpl.send(HttpClientImpl.java:931)
	at java.net.http/jdk.internal.net.http.HttpClientFacade.send(HttpClientFacade.java:133)
	at uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient.login(BlueskyClient.java:124)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher.start(BlueskyDataFetcher.java:125)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask.start(BlueskySourceTask.java:47)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:278)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:175)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:224)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:78)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:47:19,699] ERROR [bluesky-apartado-2-generative-ai|task-0] Login failure during startup (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:128)
[2025-03-22 15:47:19,699] WARN [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} After being scheduled for shutdown, the orphan task threw an uncaught exception. A newer instance of this task might be already running (org.apache.kafka.connect.runtime.WorkerTask:229)
org.apache.kafka.connect.errors.ConnectException: uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyException: Failed to log in to Bluesky
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher.start(BlueskyDataFetcher.java:129)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask.start(BlueskySourceTask.java:47)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:278)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:175)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:224)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:78)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyException: Failed to log in to Bluesky
	at uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient.login(BlueskyClient.java:142)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher.start(BlueskyDataFetcher.java:125)
	... 12 more
Caused by: java.lang.InterruptedException
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:386)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at java.net.http/jdk.internal.net.http.HttpClientImpl.send(HttpClientImpl.java:931)
	at java.net.http/jdk.internal.net.http.HttpClientFacade.send(HttpClientFacade.java:133)
	at uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient.login(BlueskyClient.java:124)
	... 13 more
[2025-03-22 15:47:19,701] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 15:47:19,701] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:47:19,702] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:19,702] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:19,702] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:19,703] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:19,703] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:19,706] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-7412cba0-22b5-4658-977d-2f10536b3df1 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1173)
[2025-03-22 15:47:19,707] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 15:47:19,708] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-03-22 15:47:19,708] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:19,708] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:19,708] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:19,711] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:19,714] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:19,716] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:19,716] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:19,716] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:19,716] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 15:47:19,718] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 15:47:19,719] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-03-22 15:47:25,237] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 15:47:25,238] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 15:47:25,239] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 15:47:25,249] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,339] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,341] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,346] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,346] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,352] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,417] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,420] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,421] INFO Scanning plugins with ServiceLoaderScanner took 173 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:47:25,421] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,443] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,443] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,458] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,458] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2 (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:25,693] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:25,698] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:47:26,196] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:47:26,196] INFO Scanning plugins with ReflectionScanner took 775 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:47:26,198] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.2/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.2
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,198] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,199] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,200] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,201] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:47:26,202] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,202] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,203] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,204] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,205] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:47:26,222] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 15:47:26,222] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 15:47:26,223] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:47:26,244] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:47:26,244] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,244] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,244] INFO Kafka startTimeMs: 1742658446244 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,338] INFO Kafka cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 15:47:26,338] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:47:26,340] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:26,340] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:26,340] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:26,343] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 15:47:26,347] INFO Logging initialized @1307ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 15:47:26,361] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 15:47:26,361] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 15:47:26,371] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 15:47:26,387] INFO Started http_8083@24d097c8{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 15:47:26,387] INFO Started @1346ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 15:47:26,393] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:47:26,393] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 15:47:26,393] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:47:26,393] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 15:47:26,394] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:47:26,394] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 15:47:26,401] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,416] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,416] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,416] INFO Kafka startTimeMs: 1742658446416 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,418] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,418] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,425] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:47:26,436] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,436] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,436] INFO Kafka startTimeMs: 1742658446436 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,437] INFO Kafka Connect worker initialization took 1200ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 15:47:26,438] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 15:47:26,438] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 15:47:26,439] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 15:47:26,439] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 15:47:26,439] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 15:47:26,439] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:47:26,440] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:47:26,441] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:47:26,441] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,442] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,442] INFO Kafka startTimeMs: 1742658446441 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,452] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 15:47:26,460] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:47:26,469] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,469] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 15:47:26,469] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 15:47:26,470] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 15:47:26,479] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:47:26,479] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,479] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,479] INFO Kafka startTimeMs: 1742658446479 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,482] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:47:26,484] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,488] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,500] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:47:26,501] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,501] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,501] INFO Kafka startTimeMs: 1742658446501 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,505] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,507] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,508] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,509] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,522] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,523] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,524] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,551] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:47:26,551] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:47:26,551] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 15:47:26,552] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 15:47:26,552] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:47:26,556] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:47:26,558] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,560] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:47:26,561] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,561] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,561] INFO Kafka startTimeMs: 1742658446561 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,561] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:47:26,562] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,564] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:47:26,564] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,564] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,564] INFO Kafka startTimeMs: 1742658446564 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,565] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,566] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,567] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:47:26,567] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,567] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,567] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,567] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,567] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,570] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,570] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,570] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,571] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,571] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,579] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:47:26,580] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:47:26,581] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 15:47:26,581] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:47:26,585] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:47:26,585] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,587] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:47:26,588] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,588] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,588] INFO Kafka startTimeMs: 1742658446588 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,588] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:47:26,589] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,591] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:47:26,591] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,591] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,591] INFO Kafka startTimeMs: 1742658446591 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,591] INFO [Producer clientId=connect-cluster-configs] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,593] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,594] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:47:26,594] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:47:26,597] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,601] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:47:26,601] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:47:26,602] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:47:26,602] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:47:26,603] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:47:26,603] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 15:47:26,603] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 15:47:26,605] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,606] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 15:47:26,607] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 15:47:26,607] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:47:26,610] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:47:26,611] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=13, memberId='connect-127.0.1.1:8083-4508cee5-aadf-4c80-92a3-8ca3351d1d1a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 15:47:26,619] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=13, memberId='connect-127.0.1.1:8083-4508cee5-aadf-4c80-92a3-8ca3351d1d1a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 15:47:26,619] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 13 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-4508cee5-aadf-4c80-92a3-8ca3351d1d1a', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed, mysql-sink-bluesky], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0, mysql-sink-bluesky-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 15:47:26,619] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-22 15:47:26,619] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 32, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-22 15:47:26,623] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-22 15:47:26,623] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 15:47:26,625] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:47:26,625] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:47:26,627] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:47:26,627] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:47:26,628] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:47:26,630] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:47:26,630] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:47:26,630] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:47:26,630] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:47:26,630] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:47:26,630] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:47:26,630] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:47:26,630] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:47:26,631] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:47:26,631] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:47:26,631] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:47:26,631] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,631] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,631] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:47:26,632] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:47:26,632] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:47:26,632] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,632] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,632] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:47:26,633] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,634] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,634] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-22 15:47:26,634] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,634] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-22 15:47:26,634] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:47:26,633] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:47:26,634] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.2 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:47:26,632] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,635] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:47:26,635] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,635] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:47:26,635] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:47:26,635] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:47:26,636] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:47:26,636] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 15:47:26,637] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.2 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:47:26,635] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:47:26,636] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:47:26,636] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:47:26,637] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:47:26,637] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:47:26,637] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:47:26,637] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:47:26,637] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:47:26,638] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:47:26,638] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:47:26,638] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:47:26,638] INFO [file-source-distributed|worker] Starting file source connector reading from /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-22 15:47:26,639] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:47:26,639] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,640] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:47:26,640] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:47:26,640] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,641] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:47:26,641] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,644] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:47:26,644] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:47:26,644] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:47:26,645] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,646] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:47:26,646] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,646] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,646] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742658446646 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,646] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:47:26,647] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:47:26,647] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,648] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,649] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:47:26,649] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,649] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,649] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742658446649 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,653] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:47:26,653] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:47:26,653] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:47:26,654] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:47:26,654] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_apartado_2 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-22 15:47:26,654] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-22 15:47:26,658] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:47:26,658] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:47:26,658] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:47:26,658] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742658446658 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:47:26,660] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 15:47:26,660] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 15:47:26,660] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:47:26,661] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,663] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 15:47:26,663] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,663] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-22 15:47:26,664] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/bluesky_db
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = generative_ai_posts
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-22 15:47:26,664] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:47:26,664] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-22 15:47:26,664] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:47:26,664] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:47:26,665] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 15:47:26,665] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 15:47:26,666] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-22 15:47:26,666] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,667] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:47:26,667] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:47:26,668] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-22 15:47:26,668] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-22 15:47:26,669] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-22 15:47:26,672] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 15:47:26,673] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:47:26,676] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-22 15:47:26,676] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:47:26,683] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-4b178dfe-d9bf-4584-90ec-548725d32772 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:47:26,683] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 15:47:26,684] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-mysql-sink-bluesky-0-4b178dfe-d9bf-4584-90ec-548725d32772', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-22 15:47:26,689] INFO Started o.e.j.s.ServletContextHandler@41092c8{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 15:47:26,689] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 15:47:26,689] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 15:47:26,690] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 3: {connector-consumer-mysql-sink-bluesky-0-4b178dfe-d9bf-4584-90ec-548725d32772=Assignment(partitions=[bluesky_apartado_2-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-22 15:47:26,693] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-mysql-sink-bluesky-0-4b178dfe-d9bf-4584-90ec-548725d32772', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-22 15:47:26,693] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_apartado_2-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-22 15:47:26,693] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-22 15:47:26,695] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-22 15:47:26,697] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_apartado_2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:47:26,736] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 15:47:26,824] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-22 15:47:26,824] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 15:47:26,835] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:47:26,837] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
[2025-03-22 15:47:26,838] INFO [mysql-sink-bluesky|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:178)
[2025-03-22 15:47:26,839] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Revoke previously assigned partitions bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-03-22 15:47:26,840] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Member connector-consumer-mysql-sink-bluesky-0-4b178dfe-d9bf-4584-90ec-548725d32772 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-03-22 15:47:26,841] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:47:26,841] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:47:27,201] INFO [mysql-sink-bluesky|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:47:27,202] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:27,202] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:47:27,202] INFO [mysql-sink-bluesky|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:47:27,205] INFO [mysql-sink-bluesky|task-0] App info kafka.consumer for connector-consumer-mysql-sink-bluesky-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:19,862] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 15:52:19,863] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 15:52:19,875] INFO Stopped http_8083@24d097c8{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 15:52:19,877] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 15:52:19,887] INFO Stopped o.e.j.s.ServletContextHandler@41092c8{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 15:52:19,888] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 15:52:19,888] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 15:52:19,888] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 15:52:19,888] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:52:19,888] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:52:19,889] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:52:19,889] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:52:19,889] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 15:52:19,889] INFO [mysql-sink-bluesky|worker] Stopping connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:52:19,889] INFO [mysql-sink-bluesky|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:52:19,889] INFO [mysql-sink-bluesky|worker] Completed shutdown for WorkerConnector{id=mysql-sink-bluesky} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:52:19,889] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:52:19,889] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:52:19,891] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:52:19,891] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:52:19,892] INFO [mysql-sink-bluesky|task-0] Stopping task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:52:20,170] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:52:20,184] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:20,185] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:20,185] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:20,186] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:20,188] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:24,894] ERROR [bluesky-apartado-2-generative-ai|task-0] Graceful stop of task bluesky-apartado-2-generative-ai-0 failed. (org.apache.kafka.connect.runtime.Worker:1074)
[2025-03-22 15:52:24,898] INFO [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 0 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:52:24,899] INFO [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms. (org.apache.kafka.clients.producer.KafkaProducer:1407)
[2025-03-22 15:52:24,907] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:52:24,910] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:52:24,912] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:24,912] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:24,912] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:24,913] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:24,914] INFO App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:24,918] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:24,919] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:24,919] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:24,920] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:24,922] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:24,922] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:52:24,923] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:52:25,275] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:25,275] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,276] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,276] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:25,291] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:25,291] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:52:25,292] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 15:52:25,292] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:52:25,292] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:52:25,294] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:25,295] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,295] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,295] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:25,295] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:25,295] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:52:25,295] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:52:25,748] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:25,749] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,750] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,751] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:25,758] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:25,758] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:52:25,758] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 15:52:25,759] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 15:52:25,762] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 15:52:25,763] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:52:25,764] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:52:25,768] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:25,768] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,769] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:25,769] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:25,769] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:25,770] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:52:25,770] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:52:26,261] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:26,262] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:26,264] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:26,265] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:26,272] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:26,273] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:52:26,273] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 15:52:26,273] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:26,273] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:26,273] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:26,274] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:26,274] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 15:52:26,544] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:52:27,286] ERROR [bluesky-apartado-2-generative-ai|task-0] Failure during login (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:141)
java.lang.InterruptedException
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:386)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at java.net.http/jdk.internal.net.http.HttpClientImpl.send(HttpClientImpl.java:931)
	at java.net.http/jdk.internal.net.http.HttpClientFacade.send(HttpClientFacade.java:133)
	at uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient.login(BlueskyClient.java:124)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher.start(BlueskyDataFetcher.java:125)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask.start(BlueskySourceTask.java:47)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:278)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:175)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:224)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:78)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:52:27,289] ERROR [bluesky-apartado-2-generative-ai|task-0] Login failure during startup (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:128)
[2025-03-22 15:52:27,290] WARN [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} After being scheduled for shutdown, the orphan task threw an uncaught exception. A newer instance of this task might be already running (org.apache.kafka.connect.runtime.WorkerTask:229)
org.apache.kafka.connect.errors.ConnectException: uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyException: Failed to log in to Bluesky
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher.start(BlueskyDataFetcher.java:129)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask.start(BlueskySourceTask.java:47)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:278)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:175)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:224)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:78)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyException: Failed to log in to Bluesky
	at uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient.login(BlueskyClient.java:142)
	at uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher.start(BlueskyDataFetcher.java:125)
	... 12 more
Caused by: java.lang.InterruptedException
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:386)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at java.net.http/jdk.internal.net.http.HttpClientImpl.send(HttpClientImpl.java:931)
	at java.net.http/jdk.internal.net.http.HttpClientFacade.send(HttpClientFacade.java:133)
	at uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient.login(BlueskyClient.java:124)
	... 13 more
[2025-03-22 15:52:27,291] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 15:52:27,292] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:52:27,292] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:27,292] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:27,293] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:27,293] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:27,293] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:27,298] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-4508cee5-aadf-4c80-92a3-8ca3351d1d1a sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1173)
[2025-03-22 15:52:27,299] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 15:52:27,300] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-03-22 15:52:27,300] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:27,300] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:27,300] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:27,305] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:27,307] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:27,308] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:27,308] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:27,308] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:27,309] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 15:52:27,311] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 15:52:27,311] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2025-03-22 15:52:30,354] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-22 15:52:30,356] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/david/Desktop/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/confluentinc-kafka-connect-jdbc-10.8.2:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/david/Desktop/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, aarch64, 6.8.0-55-generic
	os.vcpus = 5
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-22 15:52:30,356] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-22 15:52:30,366] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:52:30,459] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:52:30,462] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:52:30,466] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:52:30,467] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:52:30,470] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:52:30,471] INFO Scanning plugins with ServiceLoaderScanner took 106 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:52:30,471] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:52:30,493] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:52:30,493] INFO Loading plugin from: /home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:52:30,509] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:52:30,509] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-22 15:52:31,171] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-22 15:52:31,172] INFO Scanning plugins with ReflectionScanner took 701 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-22 15:52:31,173] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,176] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,177] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,178] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,179] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,180] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,181] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-22 15:52:31,181] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,182] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,183] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,184] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-22 15:52:31,204] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/david/Desktop/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-22 15:52:31,205] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-22 15:52:31,206] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:52:31,228] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:52:31,228] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,229] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,229] INFO Kafka startTimeMs: 1742658751228 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,320] INFO Kafka cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-22 15:52:31,321] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:52:31,323] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:52:31,323] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:52:31,323] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:52:31,325] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-22 15:52:31,330] INFO Logging initialized @1181ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-22 15:52:31,344] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-22 15:52:31,345] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-22 15:52:31,355] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-22 15:52:31,365] INFO Started http_8083@54d46c8{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-22 15:52:31,365] INFO Started @1217ms (org.eclipse.jetty.server.Server:415)
[2025-03-22 15:52:31,378] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:52:31,379] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-22 15:52:31,379] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:52:31,379] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-22 15:52:31,379] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:52:31,379] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-22 15:52:31,381] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:52:31,387] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,387] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,387] INFO Kafka startTimeMs: 1742658751387 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,389] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:52:31,390] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:52:31,396] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-22 15:52:31,406] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,406] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,406] INFO Kafka startTimeMs: 1742658751406 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,407] INFO Kafka Connect worker initialization took 1052ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-22 15:52:31,407] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-22 15:52:31,408] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-22 15:52:31,408] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-22 15:52:31,409] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-22 15:52:31,409] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-22 15:52:31,409] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:52:31,410] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-22 15:52:31,412] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-22 15:52:31,412] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,412] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,412] INFO Kafka startTimeMs: 1742658751412 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,422] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-22 15:52:31,432] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:52:31,438] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-22 15:52:31,438] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-22 15:52:31,439] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-03-22 15:52:31,443] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,453] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:52:31,453] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,454] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,454] INFO Kafka startTimeMs: 1742658751453 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,460] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:52:31,474] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,475] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,492] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:52:31,493] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,493] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,493] INFO Kafka startTimeMs: 1742658751493 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,496] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,499] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:52:31,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,502] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,502] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,502] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,517] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,517] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,543] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:52:31,543] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:52:31,543] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-22 15:52:31,544] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-22 15:52:31,544] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:52:31,549] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:52:31,550] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,552] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:52:31,553] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,553] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,553] INFO Kafka startTimeMs: 1742658751553 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,554] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:52:31,556] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,555] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,559] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:52:31,559] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,559] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,559] INFO Kafka startTimeMs: 1742658751559 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,561] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,562] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:52:31,562] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,562] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,562] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,562] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,562] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,565] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,565] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,565] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,566] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,566] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,576] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:52:31,576] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:52:31,577] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-22 15:52:31,577] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-22 15:52:31,585] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:52:31,586] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,588] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:52:31,588] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,588] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,589] INFO Kafka startTimeMs: 1742658751588 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,589] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 15:52:31,589] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,590] INFO [Producer clientId=connect-cluster-configs] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,591] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 15:52:31,592] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,592] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,592] INFO Kafka startTimeMs: 1742658751592 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,594] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,595] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-22 15:52:31,596] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-22 15:52:31,600] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 15:52:31,604] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:52:31,605] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:52:31,605] INFO Successfully processed removal of connector 'bluesky-generativeAI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-22 15:52:31,606] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-22 15:52:31,606] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-22 15:52:31,606] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-22 15:52:31,606] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-22 15:52:31,613] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,616] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 15:52:31,616] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 15:52:31,616] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:52:31,621] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 15:52:31,623] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=15, memberId='connect-127.0.1.1:8083-8fce07f0-c6c9-4aff-bcec-8414885ec50e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 15:52:31,625] INFO Started o.e.j.s.ServletContextHandler@7d75940{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-22 15:52:31,625] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-22 15:52:31,625] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-22 15:52:31,630] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=15, memberId='connect-127.0.1.1:8083-8fce07f0-c6c9-4aff-bcec-8414885ec50e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 15:52:31,631] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 15 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-8fce07f0-c6c9-4aff-bcec-8414885ec50e', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[bluesky-apartado-2-generative-ai, file-source-distributed, mysql-sink-bluesky], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0, mysql-sink-bluesky-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 15:52:31,631] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-22 15:52:31,631] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 32, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-22 15:52:31,633] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-22 15:52:31,633] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 15:52:31,634] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:52:31,634] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:52:31,634] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 15:52:31,634] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:52:31,634] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:52:31,634] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 15:52:31,636] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:969)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:949)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:949)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:967)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2004)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$39(DistributedHerder.java:2056)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:52:31,639] ERROR [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Couldn't instantiate task mysql-sink-bluesky-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2058)
org.apache.kafka.connect.errors.ConnectException: Failed to start task mysql-sink-bluesky-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2049)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$39(DistributedHerder.java:2056)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:52:31,638] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:52:31,638] INFO [bluesky-apartado-2-generative-ai|task-0] Creating task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 15:52:31,637] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:52:31,636] INFO [bluesky-apartado-2-generative-ai|worker] Creating connector bluesky-apartado-2-generative-ai of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:52:31,636] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 15:52:31,641] ERROR [mysql-sink-bluesky|worker] Failed to start connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:337)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:313)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:2105)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$44(DistributedHerder.java:2111)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 15:52:31,642] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:52:31,642] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:52:31,643] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,643] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,644] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:52:31,644] INFO [bluesky-apartado-2-generative-ai|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 15:52:31,644] INFO [bluesky-apartado-2-generative-ai|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:52:31,645] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:52:31,646] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,646] INFO [bluesky-apartado-2-generative-ai|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,648] INFO [bluesky-apartado-2-generative-ai|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 15:52:31,648] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:52:31,648] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-22 15:52:31,648] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:52:31,648] INFO [bluesky-apartado-2-generative-ai|task-0] Instantiated task bluesky-apartado-2-generative-ai-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 15:52:31,649] INFO [bluesky-apartado-2-generative-ai|worker] Instantiated connector bluesky-apartado-2-generative-ai with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:52:31,649] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 15:52:31,649] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-22 15:52:31,649] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:52:31,650] INFO [bluesky-apartado-2-generative-ai|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 15:52:31,650] INFO [bluesky-apartado-2-generative-ai|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 15:52:31,650] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 15:52:31,650] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-apartado-2-generative-ai-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 15:52:31,650] INFO [bluesky-apartado-2-generative-ai|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-apartado-2-generative-ai-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 15:52:31,650] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:52:31,650] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:52:31,651] INFO [bluesky-apartado-2-generative-ai|worker] Finished creating connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:52:31,651] INFO [bluesky-apartado-2-generative-ai|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 15:52:31,651] INFO [bluesky-apartado-2-generative-ai|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:52:31,651] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 15:52:31,651] INFO [bluesky-apartado-2-generative-ai|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,652] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:52:31,652] INFO [bluesky-apartado-2-generative-ai|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-22 15:52:31,652] INFO [bluesky-apartado-2-generative-ai|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-apartado-2-generative-ai-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:52:31,652] INFO [bluesky-apartado-2-generative-ai|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,652] INFO [file-source-distributed|worker] Starting file source connector reading from /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-22 15:52:31,653] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,654] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-22 15:52:31,655] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 15:52:31,655] INFO [bluesky-apartado-2-generative-ai|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:52:31,656] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,656] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,656] INFO [bluesky-apartado-2-generative-ai|task-0] Kafka startTimeMs: 1742658751656 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,656] ERROR [mysql-sink-bluesky|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'mysql-sink-bluesky' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2113)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: mysql-sink-bluesky
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$42(DistributedHerder.java:2083)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:339)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:2105)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$44(DistributedHerder.java:2111)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.8.1', encodedVersion=3.8.1, type=sink, typeName='sink', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.8.1', encodedVersion=3.8.1, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, name='uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector', version='0.0.1', encodedVersion=0.0.1, type=source, typeName='source', location='file:/home/david/Desktop/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:313)
	... 6 more
[2025-03-22 15:52:31,657] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-22 15:52:31,658] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 15:52:31,658] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 15:52:31,658] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742658751658 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 15:52:31,662] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,662] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 15:52:31,664] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 15:52:31,664] INFO [bluesky-apartado-2-generative-ai|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=d-ramirez.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=yshh-p3mg-wxpg-h5i6, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_apartado_2, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-apartado-2-generative-ai, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=GenerativeAI, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-22 15:52:31,665] INFO [bluesky-apartado-2-generative-ai|task-0] AbstractConfig values: 
	bluesky.identity = d-ramirez.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = GenerativeAI
	bluesky.topic = bluesky_apartado_2
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:52:31,664] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/david/Desktop/kafka_2.13-3.8.1/apartado1.csv
	topic = apartado-1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 15:52:31,665] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:52:31,665] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:52:31,666] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-apartado-2-generative-ai
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,666] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-22 15:52:31,667] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 15:52:31,668] INFO [bluesky-apartado-2-generative-ai|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-22 15:52:31,726] INFO [bluesky-apartado-2-generative-ai|task-0] Logging into Bluesky as d-ramirez.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-22 15:52:32,383] INFO [bluesky-apartado-2-generative-ai|task-0] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-22 15:52:37,383] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:21:10.729Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:52:37,752] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:52:41,664] INFO [bluesky-apartado-2-generative-ai|task-0|offsets] WorkerSourceTask{id=bluesky-apartado-2-generative-ai-0} Committing offsets for 5 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-22 15:53:26,143] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2483)
[2025-03-22 15:53:37,384] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:54:37,385] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:55:37,385] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:56:37,387] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:57:31,514] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-22 15:57:37,386] INFO [bluesky-apartado-2-generative-ai|task-0] Polling Bluesky for GenerativeAI for posts using offset 2025-03-22T15:43:39.423Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-22 15:58:11,279] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2025-03-22 15:58:11,280] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:354)
[2025-03-22 15:58:11,284] INFO Stopped http_8083@54d46c8{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-03-22 15:58:11,285] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-03-22 15:58:11,288] INFO Stopped o.e.j.s.ServletContextHandler@7d75940{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-03-22 15:58:11,288] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:383)
[2025-03-22 15:58:11,288] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:841)
[2025-03-22 15:58:11,288] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:798)
[2025-03-22 15:58:11,288] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector bluesky-apartado-2-generative-ai (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:58:11,288] INFO [bluesky-apartado-2-generative-ai|worker] Scheduled shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:58:11,288] INFO [file-source-distributed|worker] Stopping connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:451)
[2025-03-22 15:58:11,289] INFO [file-source-distributed|worker] Scheduled shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-03-22 15:58:11,289] INFO [bluesky-apartado-2-generative-ai|worker] Stopping connector (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:68)
[2025-03-22 15:58:11,290] INFO [file-source-distributed|worker] Completed shutdown for WorkerConnector{id=file-source-distributed} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:58:11,290] INFO [bluesky-apartado-2-generative-ai|worker] Completed shutdown for WorkerConnector{id=bluesky-apartado-2-generative-ai} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-03-22 15:58:11,290] INFO [file-source-distributed|task-0] Stopping task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:58:11,291] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task bluesky-apartado-2-generative-ai-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-03-22 15:58:11,291] INFO [bluesky-apartado-2-generative-ai|task-0] Stopping task (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:53)
[2025-03-22 15:58:11,291] INFO [bluesky-apartado-2-generative-ai|task-0] [Producer clientId=connector-producer-bluesky-apartado-2-generative-ai-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:58:11,294] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:11,294] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:11,294] INFO [bluesky-apartado-2-generative-ai|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:11,294] INFO [bluesky-apartado-2-generative-ai|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:11,295] INFO [bluesky-apartado-2-generative-ai|task-0] App info kafka.producer for connector-producer-bluesky-apartado-2-generative-ai-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:11,974] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:58:11,986] INFO [file-source-distributed|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:11,987] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:11,987] INFO [file-source-distributed|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:11,988] INFO [file-source-distributed|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:11,988] INFO [file-source-distributed|task-0] App info kafka.producer for connector-producer-file-source-distributed-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:11,996] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:58:11,998] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:58:12,003] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,003] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,003] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,003] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,003] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,006] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:58:12,006] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:58:12,009] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 sent an invalid full fetch response with extraIds=(LmGjEukESoSMrPpq-3XYTQ), response=() (org.apache.kafka.clients.FetchSessionHandler:555)
[2025-03-22 15:58:12,011] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,011] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,011] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,011] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,013] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,013] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:58:12,013] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2025-03-22 15:58:12,014] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:58:12,014] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:58:12,017] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,017] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,017] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,017] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,018] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,018] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:58:12,018] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:58:12,260] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,261] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,262] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,262] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,271] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,271] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:58:12,271] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:410)
[2025-03-22 15:58:12,272] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:249)
[2025-03-22 15:58:12,277] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:260)
[2025-03-22 15:58:12,278] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2025-03-22 15:58:12,279] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-03-22 15:58:12,285] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,285] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,285] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,285] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,286] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,286] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 15:58:12,287] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 15:58:12,476] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,476] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,476] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,477] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,478] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,478] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:340)
[2025-03-22 15:58:12,478] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:262)
[2025-03-22 15:58:12,478] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,478] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,479] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,479] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,479] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:270)
[2025-03-22 15:58:12,480] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-8fce07f0-c6c9-4aff-bcec-8414885ec50e sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1173)
[2025-03-22 15:58:12,481] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2025-03-22 15:58:12,481] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2025-03-22 15:58:12,481] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,481] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,481] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,482] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,483] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 15:58:12,484] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 15:58:12,484] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 15:58:12,484] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 15:58:12,484] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-03-22 15:58:12,485] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:848)
[2025-03-22 15:58:12,485] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
