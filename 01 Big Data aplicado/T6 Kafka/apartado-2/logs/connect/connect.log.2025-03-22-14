[2025-03-22 14:46:04,954] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-03-22 14:46:04,955] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2025-03-22 14:46:04,955] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Client requested disconnect from node 2147483647 (org.apache.kafka.clients.NetworkClient:343)
[2025-03-22 14:46:04,956] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 14:46:04,956] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-03-22 14:46:04,956] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2025-03-22 14:46:05,055] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-22 14:48:40,002] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-22 14:48:40,008] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector mysql-sink-bluesky config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-03-22 14:48:40,011] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 14:48:40,011] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 14:48:40,014] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 14:48:40,015] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:14:48:40 +0000] "POST /connectors HTTP/1.1" 201 635 "-" "curl/8.5.0" 15 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-22 14:48:40,017] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 14:48:40,017] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a', leaderUrl='http://127.0.1.1:8083/', offset=29, connectorIds=[mysql-sink-bluesky, bluesky-apartado-2-generative-ai, file-source-distributed], taskIds=[bluesky-apartado-2-generative-ai-0, file-source-distributed-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 14:48:40,017] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 29 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 14:48:40,018] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-22 14:48:40,018] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-22 14:48:40,019] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 14:48:40,019] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 14:48:40,019] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.2 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-22 14:48:40,020] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-22 14:48:40,020] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 14:48:40,022] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 14:48:40,023] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 14:48:40,024] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-22 14:48:40,031] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Tasks [mysql-sink-bluesky-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-03-22 14:48:40,031] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-22 14:48:40,031] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-22 14:48:40,032] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-22 14:48:40,034] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-22 14:48:40,034] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-e4d00f43-3b5f-4c97-b918-71232166270a', leaderUrl='http://127.0.1.1:8083/', offset=31, connectorIds=[mysql-sink-bluesky, bluesky-apartado-2-generative-ai, file-source-distributed], taskIds=[mysql-sink-bluesky-0, bluesky-apartado-2-generative-ai-0, file-source-distributed-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-22 14:48:40,034] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 31 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-22 14:48:40,035] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-22 14:48:40,038] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-22 14:48:40,038] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-22 14:48:40,038] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 14:48:40,039] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-22 14:48:40,039] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.2 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-22 14:48:40,039] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-22 14:48:40,040] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-22 14:48:40,040] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-22 14:48:40,040] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-22 14:48:40,040] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-22 14:48:40,040] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-22 14:48:40,041] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-22 14:48:40,041] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_apartado_2]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-22 14:48:40,041] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-22 14:48:40,042] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-22 14:48:40,043] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-22 14:48:40,044] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-22 14:48:40,044] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-22 14:48:40,044] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742654920043 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-22 14:48:40,046] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_apartado_2 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-22 14:48:40,046] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-22 14:48:40,047] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-22 14:48:40,047] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/bluesky_db
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = generative_ai_posts
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-22 14:48:40,047] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-22 14:48:40,047] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 14:48:40,047] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 14:48:40,050] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-22 14:48:40,050] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-22 14:48:40,051] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-22 14:48:40,051] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-22 14:48:40,051] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-22 14:48:40,051] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-22 14:48:40,058] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: qdhbyNa-R5GeAVd10Na0Rw (org.apache.kafka.clients.Metadata:364)
[2025-03-22 14:48:40,058] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-22 14:48:40,060] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 14:48:40,064] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-1aee6e15-5abe-4fd3-bb54-5b28a9366162 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 14:48:40,064] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-22 14:48:40,066] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-1aee6e15-5abe-4fd3-bb54-5b28a9366162', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-22 14:48:40,069] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-bluesky-0-1aee6e15-5abe-4fd3-bb54-5b28a9366162=Assignment(partitions=[bluesky_apartado_2-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-22 14:48:40,071] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-1aee6e15-5abe-4fd3-bb54-5b28a9366162', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-22 14:48:40,071] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_apartado_2-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-22 14:48:40,071] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-22 14:48:40,073] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-22 14:48:40,077] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_apartado_2-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[srv-ubuntu:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-22 14:48:40,223] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-22 14:48:40,223] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-22 14:48:40,232] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-03-22 14:48:40,234] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'mysql-sink-bluesky' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='bluesky_apartado_2',partition=0,offset=0,timestamp=1742559246100) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:81)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
[2025-03-22 14:48:40,235] INFO [mysql-sink-bluesky|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:178)
[2025-03-22 14:48:40,236] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Revoke previously assigned partitions bluesky_apartado_2-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-03-22 14:48:40,236] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Member connector-consumer-mysql-sink-bluesky-0-1aee6e15-5abe-4fd3-bb54-5b28a9366162 sending LeaveGroup request to coordinator srv-ubuntu:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-03-22 14:48:40,237] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-22 14:48:40,237] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-22 14:48:40,584] INFO [mysql-sink-bluesky|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-22 14:48:40,584] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 14:48:40,584] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-22 14:48:40,584] INFO [mysql-sink-bluesky|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-22 14:48:40,586] INFO [mysql-sink-bluesky|task-0] App info kafka.consumer for connector-consumer-mysql-sink-bluesky-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-22 14:53:26,140] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2483)
[2025-03-22 14:56:57,415] INFO [0:0:0:0:0:0:0:1] - - [22/Mar/2025:14:56:57 +0000] "GET /connectors/bluesky-apartado-2-generative-ai/status HTTP/1.1" 200 186 "-" "curl/8.5.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
