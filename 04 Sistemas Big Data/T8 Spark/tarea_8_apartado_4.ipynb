{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sistemas de Big Data - Apartado 4"
      ],
      "metadata": {
        "id": "1oGcNM-0sVOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volvemos a trabajar con el conjunto de datos de pingüinos y ahora se nos pide aplicar un modelo de clasificación (la variable objetivo es la especie del pingüino). Puedes usar cualquiera de los que se implementan en MLlib (en los apuntes hemos visto el de regresión logística y el de random forests). Utiliza el 80% del conjunto de datos para entrenar el modelo y el 20% restante para obtener las predicciones y evaluar el modelo. Debes obtener cuál es la exactitud (accuracy) y la matriz de confusión, para observar qué tan bueno ha sido el resultado. Comenta los resultados obtenidos.\n",
        "\n",
        "Debes implementarlo mediante un cuaderno de Google Colab, utilizando PySpark y la librería MLlib."
      ],
      "metadata": {
        "id": "ew_fV3IosYW0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LUi7zj9mi9lj"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.sql.functions import when, col, isnan, isnull\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Penguins_clustering\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/tnavarrete-iedib/bigdata-24-25/refs/heads/main/penguins_size.csv\"\n",
        "\n",
        "!wget -q $url -O penguins_size.csv\n",
        "\n",
        "penguins_df = spark.read.csv(\"penguins_size.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiamos el CSV\n",
        "for column in penguins_df.columns:\n",
        "    penguins_df = penguins_df.withColumn(\n",
        "        column,\n",
        "        when(\n",
        "            (col(column) == \"\") | (col(column) == \"NA\") | (col(column) == \"null\"),\n",
        "            None\n",
        "        ).otherwise(col(column))\n",
        "    )\n",
        "\n",
        "penguins_clean = penguins_df.na.drop()\n",
        "\n",
        "# Formateamos los datos\n",
        "penguins_clean = penguins_clean.withColumn(\"culmen_length_mm\", penguins_clean[\"culmen_length_mm\"].cast(DoubleType()))\n",
        "penguins_clean = penguins_clean.withColumn(\"culmen_depth_mm\", penguins_clean[\"culmen_depth_mm\"].cast(DoubleType()))\n",
        "penguins_clean = penguins_clean.withColumn(\"flipper_length_mm\", penguins_clean[\"flipper_length_mm\"].cast(DoubleType()))\n",
        "penguins_clean = penguins_clean.withColumn(\"body_mass_g\", penguins_clean[\"body_mass_g\"].cast(DoubleType()))\n",
        "\n",
        "print(f\"\\nFilas originales: {penguins_df.count()}\")\n",
        "print(f\"Filas después de elimiar NA's: {penguins_clean.count()}\")\n",
        "\n",
        "print(\"\\nDistribución:\")\n",
        "penguins_clean.groupBy(\"species\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlvZHzKyYQeQ",
        "outputId": "4fef938b-950a-49af-bdc5-8e65fe329d18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filas originales: 344\n",
            "Filas después de elimiar NA's: 334\n",
            "\n",
            "Distribución:\n",
            "+---------+-----+\n",
            "|  species|count|\n",
            "+---------+-----+\n",
            "|   Adelie|  146|\n",
            "|   Gentoo|  120|\n",
            "|Chinstrap|   68|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "species_indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\").fit(penguins_clean)\n",
        "penguin_indexed = species_indexer.transform(penguins_clean)\n",
        "\n",
        "categorical_cols = [\"island\", \"sex\"]\n",
        "\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col, outputCol=f\"{col}_index\")\n",
        "    for col in categorical_cols\n",
        "]\n",
        "\n",
        "encoders = [\n",
        "    OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_vec\")\n",
        "    for col in categorical_cols\n",
        "]\n",
        "\n",
        "numeric_cols = [\"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
        "\n",
        "assembler_inputs = numeric_cols + [f\"{col}_vec\" for col in categorical_cols]\n",
        "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
        "\n",
        "pipeline_stages = indexers + encoders + [assembler]\n",
        "pipeline = Pipeline(stages=pipeline_stages)"
      ],
      "metadata": {
        "id": "RNKxz5L9r6va"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable objetivo (species)\n",
        "species_indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\").fit(penguins_clean)\n",
        "penguin_indexed = species_indexer.transform(penguins_clean)\n",
        "\n",
        "print(\"\\nRelación especie - etiqueta:\")\n",
        "species_mapping = {float(i): label for i, label in enumerate(species_indexer.labels)}\n",
        "for index, species in species_mapping.items():\n",
        "    print(f\"Etiqueta {index} - {species}\")\n",
        "\n",
        "categorical_cols = [\"island\", \"sex\"]\n",
        "\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col, outputCol=f\"{col}_index\")\n",
        "    for col in categorical_cols\n",
        "]\n",
        "\n",
        "encoders = [\n",
        "    OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_vec\")\n",
        "    for col in categorical_cols\n",
        "]\n",
        "\n",
        "numeric_cols = [\"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
        "\n",
        "assembler_inputs = numeric_cols + [f\"{col}_vec\" for col in categorical_cols]\n",
        "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
        "\n",
        "pipeline_stages = indexers + encoders + [assembler]\n",
        "pipeline = Pipeline(stages=pipeline_stages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKRhRw9Cr7dU",
        "outputId": "a2b867aa-1802-4031-c794-b6870214bb83"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Relación especie - etiqueta:\n",
            "Etiqueta 0.0 - Adelie\n",
            "Etiqueta 1.0 - Gentoo\n",
            "Etiqueta 2.0 - Chinstrap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para preparar los datos, primero he convertido la variable objetivo a índices numéricos. También he transformado las variables categóricas con OneHotEncoder, y he usado un VectorAssembler para juntar todas las características (numéricas y categóricas) en un único vector. Todo esto lo he hecho usando un pipeline para dejarlo bien ordenado."
      ],
      "metadata": {
        "id": "-CmQsX2l5RO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos el dataset en test (20%) y entrenamiento (80%)\n",
        "train_data, test_data = penguin_indexed.randomSplit([0.8, 0.2], seed=42)\n",
        "print(f\"\\nNúmero de muestras de entrenamiento (80%): {train_data.count()}\")\n",
        "print(f\"Número de muestras de test (20%): {test_data.count()}\")\n",
        "\n",
        "pipeline_model = pipeline.fit(train_data)\n",
        "train_data_transformed = pipeline_model.transform(train_data)\n",
        "test_data_transformed = pipeline_model.transform(test_data)\n",
        "\n",
        "print(\"\\nDatos transformados:\")\n",
        "train_data_transformed.select(\"label\", \"features\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F86zX2VAr95b",
        "outputId": "85e1a632-aded-498b-e9f2-2e6229548d0f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número de muestras de entrenamiento (80%): 284\n",
            "Número de muestras de test (20%): 50\n",
            "\n",
            "Datos transformados:\n",
            "+-----+----------------------------------------+\n",
            "|label|features                                |\n",
            "+-----+----------------------------------------+\n",
            "|0.0  |[34.5,18.1,187.0,2900.0,1.0,0.0,0.0,1.0]|\n",
            "|0.0  |[35.0,17.9,190.0,3450.0,1.0,0.0,0.0,1.0]|\n",
            "|0.0  |[35.3,18.9,187.0,3800.0,1.0,0.0,0.0,1.0]|\n",
            "|0.0  |[35.5,16.2,195.0,3350.0,1.0,0.0,0.0,1.0]|\n",
            "|0.0  |[35.7,16.9,185.0,3150.0,1.0,0.0,0.0,1.0]|\n",
            "+-----+----------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.1)\n",
        "lr_model = lr.fit(train_data_transformed)\n",
        "lr_predictions = lr_model.transform(test_data_transformed)\n",
        "\n",
        "print(\"Pequeña muestra de predicciones (Regresión Logística):\")\n",
        "lr_predictions.select(\"label\", \"prediction\", \"probability\").show(5)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "print(f\"\\nPrecisión del modelo de Regresión Logística: {lr_accuracy:.4f}\")\n",
        "\n",
        "lr_pred_pd = lr_predictions.select(\"label\", \"prediction\").toPandas()\n",
        "conf_matrix_lr = pd.crosstab(\n",
        "    lr_pred_pd[\"label\"],\n",
        "    lr_pred_pd[\"prediction\"],\n",
        "    rownames=[\"Actual\"],\n",
        "    colnames=[\"Predición\"]\n",
        ")\n",
        "\n",
        "conf_matrix_lr.index = [species_mapping[i] for i in conf_matrix_lr.index]\n",
        "conf_matrix_lr.columns = [species_mapping[i] for i in conf_matrix_lr.columns]\n",
        "\n",
        "print(\"\\nMatriz de confusión (Regressió Logística):\")\n",
        "print(conf_matrix_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr0NNFlar_oG",
        "outputId": "365aaf8e-9dd4-417a-d68e-c7cea1d7a9b9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pequeña muestra de predicciones (Regresión Logística):\n",
            "+-----+----------+--------------------+\n",
            "|label|prediction|         probability|\n",
            "+-----+----------+--------------------+\n",
            "|  0.0|       0.0|[0.91487924349481...|\n",
            "|  0.0|       0.0|[0.93834666075675...|\n",
            "|  0.0|       0.0|[0.93132695308119...|\n",
            "|  0.0|       0.0|[0.94624054660143...|\n",
            "|  0.0|       0.0|[0.94609557066992...|\n",
            "+-----+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Precisión del modelo de Regresión Logística: 1.0000\n",
            "\n",
            "Matriz de confusión (Regressió Logística):\n",
            "           Adelie  Gentoo  Chinstrap\n",
            "Adelie         24       0          0\n",
            "Gentoo          0      17          0\n",
            "Chinstrap       0       0          9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    numTrees=100,\n",
        "    maxDepth=5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "rf_model = rf.fit(train_data_transformed)\n",
        "\n",
        "rf_predictions = rf_model.transform(test_data_transformed)\n",
        "\n",
        "print(\"Pequeña muestra de predicciones (Random Forest):\")\n",
        "rf_predictions.select(\"label\", \"prediction\", \"probability\").show(5)\n",
        "\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
        "print(f\"\\nPrecisión del modelo Random Forest: {rf_accuracy:.4f}\")\n",
        "\n",
        "rf_pred_pd = rf_predictions.select(\"label\", \"prediction\").toPandas()\n",
        "conf_matrix_rf = pd.crosstab(\n",
        "    rf_pred_pd[\"label\"],\n",
        "    rf_pred_pd[\"prediction\"],\n",
        "    rownames=[\"Actual\"],\n",
        "    colnames=[\"Predición\"]\n",
        ")\n",
        "\n",
        "conf_matrix_rf.index = [species_mapping[i] for i in conf_matrix_rf.index]\n",
        "conf_matrix_rf.columns = [species_mapping[i] for i in conf_matrix_rf.columns]\n",
        "\n",
        "print(\"\\nMatriz de confusión (Random Forest):\")\n",
        "print(conf_matrix_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsPcpBjTwwvK",
        "outputId": "4c2c78fe-922a-42df-f515-0858a0bd0ca7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pequeña muestra de predicciones (Random Forest):\n",
            "+-----+----------+--------------------+\n",
            "|label|prediction|         probability|\n",
            "+-----+----------+--------------------+\n",
            "|  0.0|       0.0|[0.99370481254892...|\n",
            "|  0.0|       0.0|[0.99477070402179...|\n",
            "|  0.0|       0.0|[0.96780746470233...|\n",
            "|  0.0|       0.0|[0.97453814588225...|\n",
            "|  0.0|       0.0|[0.99524120250549...|\n",
            "+-----+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Precisión del modelo Random Forest: 1.0000\n",
            "\n",
            "Matriz de confusión (Random Forest):\n",
            "           Adelie  Gentoo  Chinstrap\n",
            "Adelie         24       0          0\n",
            "Gentoo          0      17          0\n",
            "Chinstrap       0       0          9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "Después de preparar y limpiar los datos de pingüinos, probé dos modelos de clasificación para predecir la especie a partir de características físicas y categóricas: regresión logística y random forest.\n",
        "\n",
        "Ambos modelos se comportaron sorprendentemente bien, los dos alcanzaron una precisión del 100 % en el conjunto de test. Las matrices de confusión mostraron que no hubo ni un solo error de clasificación. Cada pingüino fue clasificado correctamente en su especie, lo cual me pareció bastante curioso. No es muy habitual obtener resultados tan perfectos, así que me hace pensar que este dataset está bastante limpio y que las clases están muy bien separadas.\n",
        "\n",
        "Una cosa que me llamó la atención es que incluso la regresión logística, que es un modelo bastante sencillo, funcionó igual de bien que el random forest, que en teoría es más potente. En este caso parece que no hace falta un modelo complejo para obtener buenos resultados.\n",
        "\n",
        "En resumen, fue un experimento bastante redondo. Aunque los resultados fueron excelentes, también me dejan con la duda de si el modelo se comportaría igual de bien con datos nuevos o en un contexto más real. Tal vez lo siguiente sería probar con validación cruzada o introducir algo de ruido para ver cómo aguantan los modelos."
      ],
      "metadata": {
        "id": "IKEGJUnf31E1"
      }
    }
  ]
}