{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1 - Clasificación de texto según el autor\n",
    "Construid dos modelos de diferentes autores: Josep Carner y Miquel dels Sants Oliver. Para ello, podéis usar sus obras disponibles en el Proyecto Gutenberg. Por ejemplo, de Carner, tomad la traducción de los cuentos de Mark Twain. Luego, clasificad frases en el estilo de cada uno que muestren cómo vuestro modelo las identifica correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils import open_data\n",
    "from text import *\n",
    "\n",
    "hostal = open_data(\"CA-text/hostal.txt\").read()\n",
    "wordseq = words(hostal)\n",
    "\n",
    "P_Miquel = UnigramWordModel(wordseq, 5)\n",
    "\n",
    "adventures = open_data(\"CA-text/adventures.txt\").read()\n",
    "wordseq = words(adventures)\n",
    "\n",
    "P_Josep = UnigramWordModel(wordseq, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidramirez/Documents/IEDIB/02 Modelos IA/T5 NLP/.venv/lib/python3.13/site-packages/qpsolvers/solvers/__init__.py:752: UserWarning: no QP solver found on your system, you can install solvers from PyPI by ``pip install qpsolvers[open_source_solvers]``\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from learning import NaiveBayesLearner\n",
    "\n",
    "dist = {('Miquel', 1): P_Miquel, ('Josep', 1): P_Josep}\n",
    "\n",
    "nBS = NaiveBayesLearner(dist, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(sentence, nBS):\n",
    "    sentence = sentence.lower()\n",
    "    sentence_words = words(sentence)\n",
    "    \n",
    "    return nBS(sentence_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero he probado a usar una frase extraída de los archivos CA-text/hostal.txt y CA-text/adventures.txt para comprobar si el modelo es capaz de identificar correctamente el autor de la frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"havia donat la direcció a un personatge destinat a fer molt de renou\", nBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"potser mai no bastarà mentre el món sigui món\", nBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar con otro ejemplo, le he preguntado al ChatGPT la diferencia de estilo entre los dos autores. A continuación, se muestra la respuesta del ChatGPT:\n",
    "\n",
    "```\n",
    "Diferencias resumidas:\n",
    "\t•\tJosep Carner → Poètic, refinat, musical i idealitzat.\n",
    "\t•\tMiquel dels Sants Oliver → Narratiu, directe, reflexiu i analític.\n",
    "```\n",
    "\n",
    "A raíz de esto he probado a clasificar dos frases de cada autor para ver si el modelo es capaz de diferenciar el estilo de cada uno. Pero en este caso estas frases no han sido sacadas de los archivios .txt sino generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"Els carrers, encara humits, semblaven desertar de la nit\", nBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"Amb un gest majestuós em fità un instant\", nBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 2 - Generar texto\n",
    "\n",
    "Construye modelos n-gram con n=1, n=3, n=5 y n=7 a partir de un texto de tu elección. Puede ser una obra del Proyecto Gutenberg o una noticia de prensa, por ejemplo. Observa cómo, a medida que aumenta el número de palabras consideradas, la plausibilidad del texto generado mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He optado por elegir Don Quijote de la Mancha como corpus de entranmiento para el modelo. El texto está guardado en /aima-data/ES-text/quijote.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from text import NgramWordModel\n",
    "\n",
    "def generar_texto(model, n, longitud):\n",
    "    generated_text = []\n",
    "    # Elegimos una semilla aleatoria del modelo\n",
    "    seed = random.choice(list(model.dictionary.keys()))\n",
    "    generated_text.extend(seed)\n",
    "    \n",
    "    for i in range(longitud - n):\n",
    "        last_sequence = tuple(generated_text[-(n-1):])  # Tomamos los últimos caracteres generados\n",
    "        next_possibilities = []  # Lista para guardar opciones\n",
    "\n",
    "        for k in model.dictionary.keys():  # Revisamos todos los n-gramas aprendidos\n",
    "            if k[:n-1] == last_sequence:  # Si el inicio del n-grama coincide...\n",
    "                next_possibilities.append(k[n-1])  # Guardamos la siguiente letra\n",
    "        \n",
    "        if not next_possibilities:  # Si no hay opciones, salimos\n",
    "            break\n",
    "\n",
    "        next = random.choice(next_possibilities)  # Elegimos una opción aleatoria\n",
    "        generated_text.append(next)  # La añadimos al texto generado\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Cargar texto y entrenar el modelo\n",
    "quijote = open_data(\"ES-text/quijote.txt\").read()\n",
    "wordseq = words(quijote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preparada la función hago distintas pruebas modificando la n. Y veremos que es correcta la afirmación anterior; a medida que aumentamos el número de carácteres que se tienen en cuenta el texto generado empieza a tener más sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dila dijo don juan hab a adelantado sab an que era podenco mi perro y dando consejos a quien iba cap tulo primero que habl is de darme el gobierno los deseos que duermen y mueren en sus contentos no cumpl a cuanto se llegan a los encadenados soltar los\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(3, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 3, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mire vuesa merced lo que hace se or don quijote ni quiera llevar las cosas tan por los cabos que no querr que se aprecie lo que montare la renta de la tal nsula y se descuente de mi salario gata por cantidad sancho amigo respondi don quijote ni es\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(5, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 5, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quise poner el negocio en aventura y as los hice rescatar por la misma orden que yo me rescat entregando todo el dinero al mercader para que con certeza y seguridad pudiese hacer la fianza al cual nunca descubrimos nuestro trato y secreto por el peligro que hab a cap\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(7, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 7, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por hacer una prueba con una n mucho más grande he decido usar 30. Vemos que da un buen resultado al tener más contexto.  \n",
    "Y a pesar de que algunas frases de las que genera no tienen un sentido a nivel de significado, por lo menos sí que son correctas en gran mayoría gramaticalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ni con mis obras jam s quise ni supe ofenderte luego no es verdad dijo claudia que ibas esta ma ana a desposarte con leonora la hija del rico balvastro no por cierto respondi don vicente mi mala fortuna te debi de llevar estas nuevas para que celosa me quitases\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(30, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 30, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 3 - Análisis sintáctico\n",
    "\n",
    "Aplicad las herramientas de alguna libería de Python para analizar sintácticamente la oración siguiente:  \n",
    "\n",
    "```\n",
    "Todos los seres humanos nacen libres e iguales en dignidad y derechos.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
