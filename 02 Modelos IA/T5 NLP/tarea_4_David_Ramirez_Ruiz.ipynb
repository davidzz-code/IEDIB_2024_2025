{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1 - Clasificación de texto según el autor\n",
    "Construid dos modelos de diferentes autores: Josep Carner y Miquel dels Sants Oliver. Para ello, podéis usar sus obras disponibles en el Proyecto Gutenberg. Por ejemplo, de Carner, tomad la traducción de los cuentos de Mark Twain. Luego, clasificad frases en el estilo de cada uno que muestren cómo vuestro modelo las identifica correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils import open_data\n",
    "from text import *\n",
    "\n",
    "hostal = open_data(\"CA-text/hostal.txt\").read()\n",
    "wordseq = words(hostal)\n",
    "\n",
    "P_Miquel = UnigramWordModel(wordseq, 5)\n",
    "\n",
    "adventures = open_data(\"CA-text/adventures.txt\").read()\n",
    "wordseq = words(adventures)\n",
    "\n",
    "P_Josep = UnigramWordModel(wordseq, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidramirez/Documents/IEDIB/02 Modelos IA/T5 NLP/.venv/lib/python3.10/site-packages/qpsolvers/solvers/__init__.py:752: UserWarning: no QP solver found on your system, you can install solvers from PyPI by ``pip install qpsolvers[open_source_solvers]``\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from learning import NaiveBayesLearner\n",
    "\n",
    "dist = {('Miquel', 1): P_Miquel, ('Josep', 1): P_Josep}\n",
    "\n",
    "nBS = NaiveBayesLearner(dist, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(sentence, nBS):\n",
    "    sentence = sentence.lower()\n",
    "    sentence_words = words(sentence)\n",
    "    \n",
    "    return nBS(sentence_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero he probado a usar una frase extraída de los archivos CA-text/hostal.txt y CA-text/adventures.txt para comprobar si el modelo es capaz de identificar correctamente el autor de la frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"havia donat la direcció a un personatge destinat a fer molt de renou\", nBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"potser mai no bastarà mentre el món sigui món\", nBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar con otro ejemplo, le he preguntado al ChatGPT la diferencia de estilo entre los dos autores. A continuación, se muestra la respuesta del ChatGPT:\n",
    "\n",
    "```\n",
    "Diferencias resumidas:\n",
    "\t•\tJosep Carner → Poètic, refinat, musical i idealitzat.\n",
    "\t•\tMiquel dels Sants Oliver → Narratiu, directe, reflexiu i analític.\n",
    "```\n",
    "\n",
    "A raíz de esto he probado a clasificar dos frases de cada autor para ver si el modelo es capaz de diferenciar el estilo de cada uno. Pero en este caso estas frases no han sido sacadas de los archivios .txt sino generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"Els carrers, encara humits, semblaven desertar de la nit\", nBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize(\"Amb un gest majestuós em fità un instant\", nBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 2 - Generar texto\n",
    "\n",
    "Construye modelos n-gram con n=1, n=3, n=5 y n=7 a partir de un texto de tu elección. Puede ser una obra del Proyecto Gutenberg o una noticia de prensa, por ejemplo. Observa cómo, a medida que aumenta el número de palabras consideradas, la plausibilidad del texto generado mejora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He optado por elegir Don Quijote de la Mancha como corpus de entranmiento para el modelo. El texto está guardado en /aima-data/ES-text/quijote.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from text import NgramWordModel\n",
    "\n",
    "def generar_texto(model, n, longitud):\n",
    "    generated_text = []\n",
    "    # Elegimos una semilla aleatoria del modelo\n",
    "    seed = random.choice(list(model.dictionary.keys()))\n",
    "    generated_text.extend(seed)\n",
    "    \n",
    "    for i in range(longitud - n):\n",
    "        last_sequence = tuple(generated_text[-(n-1):])  # Tomamos los últimos caracteres generados\n",
    "        next_possibilities = []  # Lista para guardar opciones\n",
    "\n",
    "        for k in model.dictionary.keys():  # Revisamos todos los n-gramas aprendidos\n",
    "            if k[:n-1] == last_sequence:  # Si el inicio del n-grama coincide...\n",
    "                next_possibilities.append(k[n-1])  # Guardamos la siguiente letra\n",
    "        \n",
    "        if not next_possibilities:  # Si no hay opciones, salimos\n",
    "            break\n",
    "\n",
    "        next = random.choice(next_possibilities)  # Elegimos una opción aleatoria\n",
    "        generated_text.append(next)  # La añadimos al texto generado\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Cargar texto y entrenar el modelo\n",
    "quijote = open_data(\"ES-text/quijote.txt\").read()\n",
    "wordseq = words(quijote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preparada la función hago distintas pruebas modificando la n. Y veremos que es correcta la afirmación anterior; a medida que aumentamos el número de carácteres que se tienen en cuenta el texto generado empieza a tener más sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el cansancio deste combate o ya vengan encaminadas por la empresa y fue luego escrito al duque de austria digan que esto hab a habiendo primero con groseras ceremonias rogado a don antonio y pregunt ndose los unos de contento mira hermano cuando yo pens que todos le dijeron que\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(3, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 3, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nadie porque as como maritornes le at ella y la otra se fueron muertas de risa y le dejaron asido de manera que fue imposible soltarse estaba pues como se ha dicho castillos eran a su parecer todas las ventas donde alojaba y que la hija del ventero no s\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(5, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 5, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que hab a sabido que en aquella casa viv a nos deb a de haber hecho aquel beneficio y en se al de que lo agradec amos hecimos zalemas a uso de moros inclinando la cabeza doblando el cuerpo y poniendo los brazos sobre el pecho de all a poco\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(7, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 7, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por hacer una prueba con una n mucho más grande he decido usar 30. Vemos que da un buen resultado al tener más contexto.  \n",
    "Y a pesar de que algunas frases de las que genera no tienen un sentido a nivel de significado, por lo menos sí que son correctas en gran mayoría gramaticalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d as ha que pudiera yo estar bogando en ellas no son los amores como los que vuestra merced piensa dijo el galeote que los m os fueron que quise tanto a una canasta de colar atestada de ropa blanca que la abrac conmigo tan fuertemente que a no quit\n"
     ]
    }
   ],
   "source": [
    "model_ngram = NgramWordModel(30, wordseq)\n",
    "\n",
    "# Generar texto\n",
    "new_text = generar_texto(model_ngram, 30, 50)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 3 - Análisis sintáctico\n",
    "\n",
    "Aplicad las herramientas de alguna libería de Python para analizar sintácticamente la oración siguiente:  \n",
    "\n",
    "```\n",
    "Tots els éssers humans neixen lliures i iguals en dignitat i drets.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sintaxis:\n",
      "Frases nominales: ['Tots els éssers humans', 'dignitat i drets']\n",
      "Verbos: ['neixar']\n",
      "Sujetos: ['éssers']\n",
      "Adjetivos: ['humans', 'lliures', 'iguals']\n",
      "Preposiciones: ['en']\n",
      "Conjunciones: ['i', 'i']\n",
      "\n",
      "Información de cada palabra:\n",
      "Palabra: Tots | Lema: tot | Etiqueta gramatical: DET | Dependencia sintáctica: det | Gobernante: els \n",
      "\n",
      "Palabra: els | Lema: el | Etiqueta gramatical: DET | Dependencia sintáctica: det | Gobernante: éssers \n",
      "\n",
      "Palabra: éssers | Lema: ésser | Etiqueta gramatical: NOUN | Dependencia sintáctica: nsubj | Gobernante: neixen \n",
      "\n",
      "Palabra: humans | Lema: humà | Etiqueta gramatical: ADJ | Dependencia sintáctica: amod | Gobernante: éssers \n",
      "\n",
      "Palabra: neixen | Lema: neixar | Etiqueta gramatical: VERB | Dependencia sintáctica: ROOT | Gobernante: neixen \n",
      "\n",
      "Palabra: lliures | Lema: lliure | Etiqueta gramatical: ADJ | Dependencia sintáctica: obj | Gobernante: neixen \n",
      "\n",
      "Palabra: i | Lema: i | Etiqueta gramatical: CCONJ | Dependencia sintáctica: cc | Gobernante: iguals \n",
      "\n",
      "Palabra: iguals | Lema: igual | Etiqueta gramatical: ADJ | Dependencia sintáctica: conj | Gobernante: lliures \n",
      "\n",
      "Palabra: en | Lema: en | Etiqueta gramatical: ADP | Dependencia sintáctica: case | Gobernante: dignitat \n",
      "\n",
      "Palabra: dignitat | Lema: dignitat | Etiqueta gramatical: NOUN | Dependencia sintáctica: nmod | Gobernante: lliures \n",
      "\n",
      "Palabra: i | Lema: i | Etiqueta gramatical: CCONJ | Dependencia sintáctica: cc | Gobernante: drets \n",
      "\n",
      "Palabra: drets | Lema: dret | Etiqueta gramatical: NOUN | Dependencia sintáctica: conj | Gobernante: dignitat \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar el modelo de lenguaje en catalán\n",
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "\n",
    "# Frase a analizar\n",
    "sentence = \"Tots els éssers humans neixen lliures i iguals en dignitat i drets\"\n",
    "\n",
    "# Analizar la frase\n",
    "doc = nlp(sentence)\n",
    "\n",
    "\n",
    "# Analizar la sintaxis de la frase\n",
    "print(\"Sintaxis:\")\n",
    "print(\"Frases nominales:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbos:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print(\"Sujetos:\", [token.text for token in doc if token.dep_ == \"nsubj\"])\n",
    "print(\"Adjetivos:\", [token.text for token in doc if token.pos_ == \"ADJ\"])\n",
    "print(\"Preposiciones:\", [token.text for token in doc if token.pos_ == \"ADP\"])\n",
    "print(\"Conjunciones:\", [token.text for token in doc if token.pos_ == \"CCONJ\"])\n",
    "print()\n",
    "\n",
    "\n",
    "# Mostrar información de cada palabra\n",
    "print(\"Información de cada palabra:\")\n",
    "for token in doc:\n",
    "    print(f\"Palabra: {token.text} | Lema: {token.lemma_} | Etiqueta gramatical: {token.pos_} | Dependencia sintáctica: {token.dep_} | Gobernante: {token.head.text} \\n\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
